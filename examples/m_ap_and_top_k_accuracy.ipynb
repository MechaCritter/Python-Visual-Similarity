{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Computing `Mean Average Precision (mAP)` and `Top-k Accuracy` for our Retrieval System**\n",
    "We'll use all images in the `validation + test dataset` as queries. For each query:\n",
    "1. Retrieve all images, rank them by similarity.\n",
    "2. Compute average precision for each query.\n",
    "3. Take the mean across all queries => mAP. This takes into consideration the ranking of the images.\n",
    "4. We will evaluate top 1 accuracy and top-k accuracy."
   ],
   "id": "bf8480748f688a15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **1. Import Necessary Libraries**",
   "id": "4a6d104abe78a29b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:41:37.557434Z",
     "start_time": "2025-01-09T21:41:27.437520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "\n",
    "from pyvisim.eval import top_k_accuracy, top_k_map\n",
    "from scripts.train import train_k_means, train_pca, train_gmm\n",
    "from pyvisim.datasets import OxfordFlowerDataset\n",
    "from pyvisim.features import DeepConvFeature\n",
    "from pyvisim.encoders import VLADEncoder, FisherVectorEncoder, Pipeline\n",
    "from pyvisim._utils import load_model, plot_and_save_barplot\n",
    "from pyvisim._config import ROOT"
   ],
   "id": "5ded369c2ee9dacc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STUD_VuNhat\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\albumentations\\__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Declare Datasets",
   "id": "ab924ba0ac7eabff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:41:37.706860Z",
     "start_time": "2025-01-09T21:41:37.574390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = OxfordFlowerDataset(purpose=\"train\")\n",
    "val_dataset = OxfordFlowerDataset(purpose=[\"validation\", \"test\"])"
   ],
   "id": "be415aef84e070cd",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:42:07.100044Z",
     "start_time": "2025-01-09T21:41:37.900991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_imgs, train_labels = zip(*[(img, label) for img, label, _ in train_dataset])\n",
    "val_imgs, val_labels = zip(*[(img, label) for img, label, _ in val_dataset])"
   ],
   "id": "45cf34f1532e800e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **3. Deep Conv Feature Extractor**\n",
   "id": "ada7c8083a999ccc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:42:07.948445Z",
     "start_time": "2025-01-09T21:42:07.122541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extractor = DeepConvFeature(\n",
    "    model=vgg16(weights=VGG16_Weights.DEFAULT),\n",
    "    layer_index=-1,  # Last conv layer\n",
    "    device=DEVICE\n",
    ")"
   ],
   "id": "fa5f60808ff1fede",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-09 22:42:07,942 - Feature_Extractor - INFO - Selected layer: features.28, Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **2. Load the PCA and KMeans models**\n",
    "\n",
    "According to my experience, VLAD works better without PCA, so VLAD vectors are computed without PCA. However, Fisher Vectors benefit significantly from PCA."
   ],
   "id": "e6aed9260089fa85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:42:07.984294Z",
     "start_time": "2025-01-09T21:42:07.971212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kmeans_model_k256 = load_model(rf'{ROOT}/models/pickle_model_files/k_means_k256_deep_features_vgg16_no_pca.pkl')\n",
    "\n",
    "gmm_model_pca = load_model(rf'{ROOT}/models/pickle_model_files/gmm_k256_deep_features_vgg16_pca.pkl')\n",
    "pca_model = load_model(rf'{ROOT}/models/pickle_model_files/pca_fisher_k256_deep_features_vgg16_feature_dim257.pkl')"
   ],
   "id": "7e5af1a108990a84",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you have not yet trained your model or saved it, you can train it using the following code (might take a while. Reduce num_clusters to make it faster. This comes at the cost of the performance, however).",
   "id": "7152fbf688cea278"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:42:08.026583Z",
     "start_time": "2025-01-09T21:42:08.022223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NUM_CLUSTERS = 256\n",
    "IMAGE_SIZE = (224, 224)\n",
    "DIM_REDUCTION_FACTOR = 2\n",
    "\n",
    "labels, paths, features = [], [], []\n",
    "for img, lbl, path in train_dataset:\n",
    "    labels.append(lbl)\n",
    "    paths.append(path)\n",
    "    features.append(extractor(img))\n",
    "\n",
    "labels = np.array(labels)\n",
    "features = np.vstack(features)\n",
    "\n",
    "pca_model= train_pca(reduction_factor=DIM_REDUCTION_FACTOR, features=features)\n",
    "reduced_features = pca_model.transform(features)\n",
    "\n",
    "kmeans_model_k256= train_k_means(n_clusters=NUM_CLUSTERS, features=features)\n",
    "\n",
    "gmm_model_pca = train_gmm(n_components=NUM_CLUSTERS, features=reduced_features)"
   ],
   "id": "a37dff311e94cce",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **3. Load the Encoders**",
   "id": "b63a88e78e223b90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:42:08.069796Z",
     "start_time": "2025-01-09T21:42:08.062796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vlad_encoder = VLADEncoder(\n",
    "    feature_extractor=extractor,\n",
    "    kmeans_model=kmeans_model_k256,\n",
    "    power_norm_weight=1.0,\n",
    ")\n",
    "\n",
    "fisher_vector_encoder = FisherVectorEncoder(\n",
    "    feature_extractor=extractor,\n",
    "    gmm_model=gmm_model_pca,\n",
    "    pca=pca_model,\n",
    "    power_norm_weight=0.5,\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_with_pca = Pipeline(\n",
    "    [vlad_encoder, fisher_vector_encoder]\n",
    ")"
   ],
   "id": "763831fb769f4137",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **4. Performance metrics**\n",
    "\n",
    "First, we prepare the data."
   ],
   "id": "246dd4be523ea126"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T21:53:42.412809Z",
     "start_time": "2025-01-09T21:42:08.079796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_paths, train_labels = zip(*[(path, label) for _, label, path in train_dataset])\n",
    "encodings_vlad = vlad_encoder.generate_encoding_map(train_paths)\n",
    "encodings_fisher = fisher_vector_encoder.generate_encoding_map(train_paths)\n",
    "encodings_pipeline = pipeline_with_pca.generate_encoding_map(train_paths)\n",
    "dataset_labels_dict = dict(zip(train_paths, train_labels))"
   ],
   "id": "b41f8223d09379ac",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **5.1. Top-k accuracy**\n",
    "\n",
    "How it works:\n",
    "- For each query, retrieve **top-k** most similar images.\n",
    "- If any of them share the same label as the query, that counts as correct.\n",
    "- The final accuracy is `num_correct_queries / num_queries`.\n",
    "\n",
    "Let's compute the top-1 accuracy (the most relevant match has to be the correct one):"
   ],
   "id": "1d6b73d975357b37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T23:24:27.046802Z",
     "start_time": "2025-01-09T21:53:42.475612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Top-1 Accuracy for VLAD with PCA\n",
    "acc_k1_vlad = top_k_accuracy(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_vlad,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=vlad_encoder,\n",
    "    k=1\n",
    ")\n",
    "print(\"Top-1 Accuracy, VLAD:\", acc_k1_vlad)"
   ],
   "id": "23424c86ecbb01c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy, VLAD: 0.6931372549019608\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T02:07:41.196259Z",
     "start_time": "2025-01-09T23:24:27.165882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Top-1 Accuracy for Fisher with PCA\n",
    "acc_k1_fisher = top_k_accuracy(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_fisher,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=fisher_vector_encoder,\n",
    "    k=1\n",
    ")\n",
    "print(\"Top-1 Accuracy, Fisher Vector:\", acc_k1_fisher)"
   ],
   "id": "725ea0423e63477f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy, Fisher Vector: 0.667156862745098\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T07:57:14.947339Z",
     "start_time": "2025-01-10T02:07:41.302458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Top-1 Accuracy for Pipeline with PCA\n",
    "acc_k1_pipeline = top_k_accuracy(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_pipeline,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=pipeline_with_pca,\n",
    "    k=1\n",
    ")\n",
    "print(\"Top-1 Accuracy, Pipeline:\", acc_k1_pipeline)"
   ],
   "id": "8e6cd79ba70cb3a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy, Pipeline: 0.6936274509803921\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Normally, we might also consider the second, third and so on.. most relevant results. In this case, we can set `k > 1`. Let's try for `k=5`:",
   "id": "8aba5dd7bfdb19f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T09:35:20.759254Z",
     "start_time": "2025-01-10T07:57:15.001806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Top-5 Accuracy for VLAD with PCA\n",
    "acc_k5_vlad = top_k_accuracy(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_vlad,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=vlad_encoder,\n",
    "    k=5\n",
    ")\n",
    "print(\"Top-5 Accuracy, VLAD:\", acc_k5_vlad)"
   ],
   "id": "153f3bf9522c1f1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy, VLAD: 0.8671568627450981\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T14:05:17.044406Z",
     "start_time": "2025-01-10T10:53:06.987149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Top-5 Accuracy for Fisher with PCA\n",
    "acc_k5_fisher = top_k_accuracy(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_fisher,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=fisher_vector_encoder,\n",
    "    k=5\n",
    ")\n",
    "print(\"Top-5 Accuracy, Fisher Vector:\", acc_k5_fisher)"
   ],
   "id": "859c2f71ffc2d0bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy, Fisher Vector: 0.8387254901960784\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-10T14:05:17.095015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Top-5 Accuracy for Pipeline with PCA\n",
    "acc_k5_pipeline = top_k_accuracy(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_pipeline,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=pipeline_with_pca,\n",
    "    k=5\n",
    ")\n",
    "print(\"Top-5 Accuracy, Pipeline:\", acc_k5_pipeline)"
   ],
   "id": "e5511937129cc4c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **5.2. Compute the mAP**",
   "id": "f4dce5e120d66eda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How it works:\n",
    "- If `k` is given, we only consider the `top-k` ranked results per query.\n",
    "- if `k=None` or omitted, we consider all results (the entire dataset).\n",
    "- For each query, we compute average precision (AP). Then we average across all queries, yielding mean average precision (mAP).\n",
    "\n",
    "Example:\n",
    "Image `a` has label `1`, and the top-6 retrieved images have labels:\n",
    "- Truth Labels: [0, 1, 1, 0 ,0, 1]\n",
    "\n",
    "**a) k=None**: we consider all results.\n",
    "- Rank 2: AP = 1/2\n",
    "- Rank 3: AP = 2/3\n",
    "- Rank 6: AP = 3/6\n",
    "- mAP = (1/2 + 2/3 + 3/6) / 6 0.278\n",
    "\n",
    "**b) k=3**:\n",
    "- Rank 2: AP = 1/2\n",
    "- Rank 3: AP = 2/3\n",
    "- mAP = (1/2 + 2/3) / 3 = 0.389\n",
    "\n",
    "First, we do it for the whole dataset:"
   ],
   "id": "b2edbd7d5eebd301"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mAP_value_vlad = top_k_map(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_vlad,  # {path: vector}\n",
    "    path_labels_dict=dataset_labels_dict,    # {path: label}\n",
    "    encoder=vlad_encoder  # or vlad_encoder, fisher_encoder\n",
    ")\n",
    "print(\"Mean Average Precision (mAP), VLAD:\", mAP_value_vlad)"
   ],
   "id": "d1250e7005751359"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mAP_value_fisher= top_k_map(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_fisher,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=fisher_vector_encoder\n",
    ")\n",
    "print(\"Mean Average Precision (mAP), Fisher Vector:\", mAP_value_fisher)"
   ],
   "id": "919df4ea7657a495"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mAP_value_pipeline = top_k_map(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_pipeline,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=pipeline_with_pca\n",
    ")\n",
    "print(\"Mean Average Precision (mAP), Pipeline:\", mAP_value_pipeline)"
   ],
   "id": "68944964839a11c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Normally, we might only care about the top results. Let's compute the mAP for the top 5 results:",
   "id": "ff0af2df9a03ed12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mAP_value_top5_vlad_pca = top_k_map(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_vlad,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=vlad_encoder,\n",
    "    k=5\n",
    ")\n",
    "print(\"Mean Average Precision (mAP) for Top-5, VLAD:\", mAP_value_top5_vlad_pca)"
   ],
   "id": "2ae67e5962caaa8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mAP_value_top5_fisher_pca = top_k_map(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_fisher,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=fisher_vector_encoder,\n",
    "    k=5\n",
    ")\n",
    "print(\"Mean Average Precision (mAP) for Top-5, Fisher Vector:\", mAP_value_top5_fisher_pca)"
   ],
   "id": "b9f51195000ecb3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mAP_value_top5_pipeline = top_k_map(\n",
    "    images=val_imgs,\n",
    "    image_labels=val_labels,\n",
    "    encoding_map=encodings_pipeline,\n",
    "    path_labels_dict=dataset_labels_dict,\n",
    "    encoder=pipeline_with_pca,\n",
    "    k=5\n",
    ")\n",
    "print(\"Mean Average Precision (mAP) for Top-5, Pipeline with PCA:\", mAP_value_top5_pipeline)"
   ],
   "id": "1d43e1d7a9881a9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Plot bar chart for mAP and top-k accuracy to compare the performance of the encoders.\n",
    "plot_and_save_barplot(\n",
    " {\n",
    "     \"VLAD\": [mAP_value_vlad, acc_k1_vlad, acc_k5_vlad],\n",
    "     \"Fisher Vector\": [mAP_value_fisher, acc_k1_fisher, acc_k5_fisher],\n",
    "     \"Pipeline\": [mAP_value_pipeline, acc_k1_pipeline, acc_k5_pipeline]\n",
    " },\n",
    "    bar_labels=[\"mAP\", \"Top-1 Accuracy\", \"Top-5 Accuracy\"],\n",
    "    title=\"Performance Metrics for VLAD, Fisher Vector, and Pipeline with PCA\",\n",
    "    ylabel=\"Value\",\n",
    "    xlabel=\"Metrics\")"
   ],
   "id": "10e00fd4d0a04d5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
