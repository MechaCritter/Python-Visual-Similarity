{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "3ee770bafa6e7488"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T21:06:03.216124Z",
     "start_time": "2024-12-02T21:05:57.705572Z"
    }
   },
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from segmentation_models_pytorch.utils.metrics import IoU\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils import save_to_hdf5, load_hdf5, load_model\n",
    "from src.datasets import ExcavatorDataset\n",
    "from src.config import IMAGE_SIZE, TRANSFORMER, DEVICE\n",
    "from models.Segmentation import DeepLabV3Model, DeepLabV3PlusModel, PyramidAttentionNetworkModel, UNetModel"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ais/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Root",
   "id": "fc16d86a2bf24138"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:06:03.236939Z",
     "start_time": "2024-12-02T21:06:03.230003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "root = f'/home/ais/Bachelorarbeit/similarity_metrics_of_images/'\n",
    "batch_size = 1"
   ],
   "id": "97d657b467258390",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Initialize models\n",
    "\n",
    "**Note**: UNEt performs quite badly (only achieves `val IoU` of 0.78)."
   ],
   "id": "820783049fff5a57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:06:05.293714Z",
     "start_time": "2024-12-02T21:06:03.299596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DeepLabV3\n",
    "dlv3 =DeepLabV3Model().model\n",
    "dlv3.load_state_dict(torch.load(f'{root}models/torch_model_files/DeepLabV3_HybridFocalDiceLoss.pt'))\n",
    "dlv3.to(DEVICE)\n",
    "dlv3.eval()\n",
    "\n",
    "# DeepLabV3Plus\n",
    "dlv3p = DeepLabV3PlusModel().model\n",
    "dlv3p.load_state_dict(torch.load(f'{root}models/torch_model_files/DeepLabV3Plus_HybridFocalDiceLoss.pt'))\n",
    "dlv3p.to(DEVICE)\n",
    "dlv3p.eval()\n",
    "\n",
    "# UNet\n",
    "unet = UNetModel().model\n",
    "unet.load_state_dict(torch.load(f'{root}models/torch_model_files/UNet_HybridFocalDiceLoss.pt'))\n",
    "unet.to(DEVICE)\n",
    "unet.eval()\n",
    "\n",
    "# Pyramid Attention Network\n",
    "pan = PyramidAttentionNetworkModel().model\n",
    "pan.load_state_dict(torch.load(f'{root}models/torch_model_files/PyramidAttentionNetwork_HybridFocalDiceLoss.pt'))\n",
    "pan.to(DEVICE)\n",
    "pan.eval()"
   ],
   "id": "3686fc5b61c0c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 22:06:03,602 - DeepLabV3 - INFO - New model created with the following info:\n",
      "                            - Encoder name: resnet18\n",
      "                            - Activation: None\n",
      "                            - Classes: 12\n",
      "2024-12-02 22:06:03,606 - DeepLabV3 - INFO - Device used for model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3104296/3960602995.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dlv3.load_state_dict(torch.load(f'{root}models/torch_model_files/DeepLabV3_HybridFocalDiceLoss.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 22:06:04,356 - DeepLabV3Plus - INFO - New model created with the following info:\n",
      "                            - Encoder name: resnet18\n",
      "                            - Activation: None\n",
      "                            - Classes: 12\n",
      "2024-12-02 22:06:04,359 - DeepLabV3Plus - INFO - Device used for model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3104296/3960602995.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dlv3p.load_state_dict(torch.load(f'{root}models/torch_model_files/DeepLabV3Plus_HybridFocalDiceLoss.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 22:06:04,717 - UNet - INFO - New model created with the following info:\n",
      "                            - Encoder name: resnet18\n",
      "                            - Activation: None\n",
      "                            - Classes: 12\n",
      "2024-12-02 22:06:04,720 - UNet - INFO - Device used for model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3104296/3960602995.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  unet.load_state_dict(torch.load(f'{root}models/torch_model_files/UNet_HybridFocalDiceLoss.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-02 22:06:05,114 - PyramidAttentionNetwork - INFO - New model created with the following info:\n",
      "                            - Encoder name: resnet18\n",
      "                            - Activation: None\n",
      "                            - Classes: 12\n",
      "2024-12-02 22:06:05,116 - PyramidAttentionNetwork - INFO - Device used for model: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3104296/3960602995.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  pan.load_state_dict(torch.load(f'{root}models/torch_model_files/PyramidAttentionNetwork_HybridFocalDiceLoss.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PAN(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): PANDecoder(\n",
       "    (fpa): FPABlock(\n",
       "      (branch1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (mid): Sequential(\n",
       "        (0): ConvBnRelu(\n",
       "          (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (down1): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(512, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (down2): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (down3): Sequential(\n",
       "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBnRelu(\n",
       "          (conv): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv2): ConvBnRelu(\n",
       "        (conv): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv1): ConvBnRelu(\n",
       "        (conv): Conv2d(1, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (gau3): GAUBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (conv2): ConvBnRelu(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (gau2): GAUBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (conv2): ConvBnRelu(\n",
       "        (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (gau1): GAUBlock(\n",
       "      (conv1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvBnRelu(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sigmoid()\n",
       "      )\n",
       "      (conv2): ConvBnRelu(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load dataset",
   "id": "3963c93c12de2e35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:06:05.336957Z",
     "start_time": "2024-12-02T21:06:05.316655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='train', transform=TRANSFORMER,one_hot_encode_mask=True)\n",
    "print(\"Number of training samples:\", num_train_imgs:=len(train_dataset))\n",
    "val_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='test', transform=TRANSFORMER, one_hot_encode_mask=True)\n",
    "print(\"Number of test samples:\", num_val_imgs:=len(val_dataset))"
   ],
   "id": "9e8be6904fa0366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1782\n",
      "Number of test samples: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ais/Bachelorarbeit/similarity_metrics_of_images/src/datasets.py:313: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  key: torch.tensor(value / 255.0, dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compute and save predicted masks",
   "id": "b5f995de2db521b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:06:05.406748Z",
     "start_time": "2024-12-02T21:06:05.373362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_iou_dlv3 = torch.zeros(num_train_imgs, dtype=torch.float32, device=DEVICE)\n",
    "train_iou_dlv3p = torch.zeros(num_train_imgs, dtype=torch.float32, device=DEVICE)\n",
    "train_iou_unet = torch.zeros(num_train_imgs, dtype=torch.float32, device=DEVICE)\n",
    "train_iou_pan = torch.zeros(num_train_imgs, dtype=torch.float32, device=DEVICE)\n",
    "train_paths = []\n",
    "\n",
    "val_iou_dlv3 = torch.zeros(num_val_imgs, dtype=torch.float32, device=DEVICE)\n",
    "val_iou_dlv3p = torch.zeros(num_val_imgs, dtype=torch.float32, device=DEVICE)\n",
    "val_iou_unet = torch.zeros(num_val_imgs, dtype=torch.float32, device=DEVICE)\n",
    "val_iou_pan = torch.zeros(num_val_imgs, dtype=torch.float32, device=DEVICE)\n",
    "val_paths = []"
   ],
   "id": "be0683ca3c1dc084",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T14:43:59.988001Z",
     "start_time": "2024-12-03T14:42:56.049252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Compute predicted masks for training set\n",
    "for i, (imgs, masks, paths) in tqdm(enumerate(train_dataset)):\n",
    "    imgs = imgs.to(DEVICE).unsqueeze(0)\n",
    "    masks = masks.to(DEVICE)\n",
    "    output_dlv3 = dlv3(imgs)\n",
    "    output_dlv3p = dlv3p(imgs)\n",
    "    output_unet = unet(imgs)\n",
    "    output_pan = pan(imgs)\n",
    "    train_iou_dlv3[i] = IoU()(output_dlv3, masks)\n",
    "    train_iou_dlv3p[i] = IoU()(output_dlv3p, masks)\n",
    "    train_iou_unet[i] = IoU()(output_unet, masks)\n",
    "    train_iou_pan[i] = IoU()(output_pan, masks)\n",
    "    train_paths.extend(paths)\n",
    "\n",
    "train_paths = [path.replace('/', '|').replace('\\\\', '|') for path in train_paths]\n",
    "save_to_hdf5(f'{root}res/model_performance/train_iou_dlv3.h5', {'train_iou': train_iou_dlv3.cpu().numpy(), 'train_paths': train_paths})\n",
    "save_to_hdf5(f'{root}res/model_performance/train_iou_dlv3p.h5', {'train_iou': train_iou_dlv3p.cpu().numpy(), 'train_paths': train_paths})\n",
    "save_to_hdf5(f'{root}res/model_performance/train_iou_unet.h5', {'train_iou': train_iou_unet.cpu().numpy(), 'train_paths': train_paths})\n",
    "save_to_hdf5(f'{root}res/model_performance/train_iou_pan.h5', {'train_iou': train_iou_pan.cpu().numpy(), 'train_paths': train_paths})\n",
    "\n",
    "# Compute predicted masks for validation set\n",
    "for i, (imgs, masks, paths) in tqdm(enumerate(val_dataset)):\n",
    "    imgs = imgs.to(DEVICE).unsqueeze(0)\n",
    "    masks = masks.to(DEVICE)\n",
    "    output_dlv3 = dlv3(imgs)\n",
    "    output_dlv3p = dlv3p(imgs)\n",
    "    output_unet = unet(imgs)\n",
    "    output_pan = pan(imgs)\n",
    "    val_iou_dlv3[i] = IoU()(output_dlv3, masks)\n",
    "    val_iou_dlv3p[i] = IoU()(output_dlv3p, masks)\n",
    "    val_iou_unet[i] = IoU()(output_unet, masks)\n",
    "    val_iou_pan[i] = IoU()(output_pan, masks)\n",
    "    val_paths.extend(paths)\n",
    "\n",
    "val_paths = [path.replace('/', '|').replace('\\\\', '|') for path in val_paths]\n",
    "save_to_hdf5(f'{root}res/model_performance/val_iou_dlv3.h5', {'val_iou': val_iou_dlv3.cpu().numpy(), 'val_paths': val_paths})\n",
    "save_to_hdf5(f'{root}res/model_performance/val_iou_dlv3p.h5', {'val_iou': val_iou_dlv3p.cpu().numpy(), 'val_paths': val_paths})\n",
    "save_to_hdf5(f'{root}res/model_performance/val_iou_unet.h5', {'val_iou': val_iou_unet.cpu().numpy(), 'val_paths': val_paths})\n",
    "save_to_hdf5(f'{root}res/model_performance/val_iou_pan.h5', {'val_iou': val_iou_pan.cpu().numpy(), 'val_paths': val_paths})\n"
   ],
   "id": "5697537b3b79eb5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1782it [00:57, 30.85it/s]\n",
      "187it [00:05, 34.29it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compute pairwise IoU differences between training and validation set",
   "id": "dd48f0783ecd414"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:51:03.178012Z",
     "start_time": "2024-12-06T06:51:03.119861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data= load_hdf5(f'{root}res/model_performance/train_iou.h5')\n",
    "train_iou = train_data['train_iou']\n",
    "train_paths = train_data['train_paths']\n",
    "\n",
    "val_data = load_hdf5(f'{root}res/model_performance/val_iou.h5')\n",
    "val_iou = val_data['val_iou']\n",
    "val_paths = val_data['val_paths']"
   ],
   "id": "1bf26cb63a6dd3c2",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/home/ais/Bachelorarbeit/similarity_metrics_of_images/res/model_performance/train_iou.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_data\u001B[38;5;241m=\u001B[39m \u001B[43mload_hdf5\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mroot\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43mres/model_performance/train_iou.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m train_iou \u001B[38;5;241m=\u001B[39m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_iou\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      3\u001B[0m train_paths \u001B[38;5;241m=\u001B[39m train_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_paths\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/Bachelorarbeit/similarity_metrics_of_images/src/utils.py:255\u001B[0m, in \u001B[0;36mload_hdf5\u001B[0;34m(file_path)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_hdf5\u001B[39m(file_path: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m    248\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;124;03m    Load data from an HDF5 file.\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;124;03m    :return: Dictionary containing data from the HDF5 file\u001B[39;00m\n\u001B[1;32m    254\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mh5py\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m    256\u001B[0m         data \u001B[38;5;241m=\u001B[39m {key: val[:] \u001B[38;5;28;01mfor\u001B[39;00m key, val \u001B[38;5;129;01min\u001B[39;00m file\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/h5py/_hl/files.py:561\u001B[0m, in \u001B[0;36mFile.__init__\u001B[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001B[0m\n\u001B[1;32m    552\u001B[0m     fapl \u001B[38;5;241m=\u001B[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001B[1;32m    553\u001B[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001B[1;32m    554\u001B[0m                      alignment_threshold\u001B[38;5;241m=\u001B[39malignment_threshold,\n\u001B[1;32m    555\u001B[0m                      alignment_interval\u001B[38;5;241m=\u001B[39malignment_interval,\n\u001B[1;32m    556\u001B[0m                      meta_block_size\u001B[38;5;241m=\u001B[39mmeta_block_size,\n\u001B[1;32m    557\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m    558\u001B[0m     fcpl \u001B[38;5;241m=\u001B[39m make_fcpl(track_order\u001B[38;5;241m=\u001B[39mtrack_order, fs_strategy\u001B[38;5;241m=\u001B[39mfs_strategy,\n\u001B[1;32m    559\u001B[0m                      fs_persist\u001B[38;5;241m=\u001B[39mfs_persist, fs_threshold\u001B[38;5;241m=\u001B[39mfs_threshold,\n\u001B[1;32m    560\u001B[0m                      fs_page_size\u001B[38;5;241m=\u001B[39mfs_page_size)\n\u001B[0;32m--> 561\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mmake_fid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muserblock_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfapl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfcpl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mswmr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mswmr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(libver, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_libver \u001B[38;5;241m=\u001B[39m libver\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/h5py/_hl/files.py:235\u001B[0m, in \u001B[0;36mmake_fid\u001B[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001B[0m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m swmr \u001B[38;5;129;01mand\u001B[39;00m swmr_support:\n\u001B[1;32m    234\u001B[0m         flags \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mACC_SWMR_READ\n\u001B[0;32m--> 235\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mh5f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfapl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfapl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    237\u001B[0m     fid \u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mopen(name, h5f\u001B[38;5;241m.\u001B[39mACC_RDWR, fapl\u001B[38;5;241m=\u001B[39mfapl)\n",
      "File \u001B[0;32mh5py/_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mh5py/h5f.pyx:102\u001B[0m, in \u001B[0;36mh5py.h5f.open\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/home/ais/Bachelorarbeit/similarity_metrics_of_images/res/model_performance/train_iou.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check that data is loaded correctly",
   "id": "5b2a1fdb480ebf1f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:07:06.521479400Z",
     "start_time": "2024-12-02T20:59:42.065988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Shape of train_iou:\", train_iou.shape)\n",
    "print(\"Number of training samples:\", len(train_paths))\n",
    "print(\"Shape of val_iou:\", val_iou.shape)\n",
    "print(\"Number of validation samples:\", len(val_paths))"
   ],
   "id": "26d7cf21a111a612",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_iou: (1782,)\n",
      "Number of training samples: 270505\n",
      "Shape of val_iou: (187,)\n",
      "Number of validation samples: 29093\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compute pairwise IoU differences between training and validation set",
   "id": "9ad768d0a39950da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:53:40.379350Z",
     "start_time": "2024-12-06T06:53:38.880085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in ['dlv3', 'dlv3p', 'unet', 'pan']:\n",
    "    train_iou = load_hdf5(f'{root}res/model_performance/train_iou_{model}.h5')['train_iou']\n",
    "    val_iou = load_hdf5(f'{root}res/model_performance/val_iou_{model}.h5')['val_iou']\n",
    "    idx_pair = []\n",
    "    iou_diff = []\n",
    "\n",
    "    for i, t_iou in enumerate(train_iou):\n",
    "        for j, v_iou in enumerate(val_iou):\n",
    "            iou_diff.append(t_iou - v_iou)\n",
    "            idx_pair.append((i, j))\n",
    "\n",
    "    save_to_hdf5(f'{root}res/model_performance/iou_diff_{model}.h5', {'iou_diff': iou_diff, 'idx_pair': idx_pair})\n"
   ],
   "id": "40e51caf89251022",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check that data is saved correctly",
   "id": "6f79bfdd403e312"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:56:24.294612Z",
     "start_time": "2024-12-06T06:56:24.266322Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comp_data = load_hdf5(f'{root}res/model_performance/iou_diff_dlv3.h5')\n",
    "print(\"Shape of iou_diff:\", comp_data['iou_diff'].shape)\n",
    "print(\"Number of pairs:\", len(comp_data['idx_pair']))\n",
    "for i in range(100):\n",
    "    print(f\"Pair {i}: {comp_data['iou_diff'][i+1000]}\")\n",
    "    print(f\"Index pair {i}: {comp_data['idx_pair'][i+1000]}\")"
   ],
   "id": "20afd4d8dd05c2e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of iou_diff: (333234,)\n",
      "Number of pairs: 333234\n",
      "Pair 0: 0.033710867166519165\n",
      "Index pair 0: [ 5 65]\n",
      "Pair 1: 0.024200350046157837\n",
      "Index pair 1: [ 5 66]\n",
      "Pair 2: -0.02996695041656494\n",
      "Index pair 2: [ 5 67]\n",
      "Pair 3: 0.0017576515674591064\n",
      "Index pair 3: [ 5 68]\n",
      "Pair 4: -0.06966686248779297\n",
      "Index pair 4: [ 5 69]\n",
      "Pair 5: 0.07387089729309082\n",
      "Index pair 5: [ 5 70]\n",
      "Pair 6: -0.20941200852394104\n",
      "Index pair 6: [ 5 71]\n",
      "Pair 7: -0.0359133780002594\n",
      "Index pair 7: [ 5 72]\n",
      "Pair 8: -0.05518332123756409\n",
      "Index pair 8: [ 5 73]\n",
      "Pair 9: -0.10235503315925598\n",
      "Index pair 9: [ 5 74]\n",
      "Pair 10: -0.11664527654647827\n",
      "Index pair 10: [ 5 75]\n",
      "Pair 11: -0.08075404167175293\n",
      "Index pair 11: [ 5 76]\n",
      "Pair 12: -0.11365470290184021\n",
      "Index pair 12: [ 5 77]\n",
      "Pair 13: -0.11434110999107361\n",
      "Index pair 13: [ 5 78]\n",
      "Pair 14: -0.013910651206970215\n",
      "Index pair 14: [ 5 79]\n",
      "Pair 15: -0.12485209107398987\n",
      "Index pair 15: [ 5 80]\n",
      "Pair 16: -0.10711178183555603\n",
      "Index pair 16: [ 5 81]\n",
      "Pair 17: -0.06136474013328552\n",
      "Index pair 17: [ 5 82]\n",
      "Pair 18: -0.029033809900283813\n",
      "Index pair 18: [ 5 83]\n",
      "Pair 19: -0.05774679780006409\n",
      "Index pair 19: [ 5 84]\n",
      "Pair 20: -0.081126868724823\n",
      "Index pair 20: [ 5 85]\n",
      "Pair 21: -0.03321951627731323\n",
      "Index pair 21: [ 5 86]\n",
      "Pair 22: -0.017238706350326538\n",
      "Index pair 22: [ 5 87]\n",
      "Pair 23: 0.005940109491348267\n",
      "Index pair 23: [ 5 88]\n",
      "Pair 24: -0.04066494107246399\n",
      "Index pair 24: [ 5 89]\n",
      "Pair 25: -0.0782361626625061\n",
      "Index pair 25: [ 5 90]\n",
      "Pair 26: -0.054308682680130005\n",
      "Index pair 26: [ 5 91]\n",
      "Pair 27: 0.10439285635948181\n",
      "Index pair 27: [ 5 92]\n",
      "Pair 28: 0.10348424315452576\n",
      "Index pair 28: [ 5 93]\n",
      "Pair 29: 0.08300670981407166\n",
      "Index pair 29: [ 5 94]\n",
      "Pair 30: 0.03845980763435364\n",
      "Index pair 30: [ 5 95]\n",
      "Pair 31: -0.13122287392616272\n",
      "Index pair 31: [ 5 96]\n",
      "Pair 32: -0.011258959770202637\n",
      "Index pair 32: [ 5 97]\n",
      "Pair 33: -0.04157912731170654\n",
      "Index pair 33: [ 5 98]\n",
      "Pair 34: -0.001196146011352539\n",
      "Index pair 34: [ 5 99]\n",
      "Pair 35: -0.2224867045879364\n",
      "Index pair 35: [  5 100]\n",
      "Pair 36: -0.05414596199989319\n",
      "Index pair 36: [  5 101]\n",
      "Pair 37: -0.04808071255683899\n",
      "Index pair 37: [  5 102]\n",
      "Pair 38: 0.024698108434677124\n",
      "Index pair 38: [  5 103]\n",
      "Pair 39: -0.019382983446121216\n",
      "Index pair 39: [  5 104]\n",
      "Pair 40: -0.04733720421791077\n",
      "Index pair 40: [  5 105]\n",
      "Pair 41: 0.0501038134098053\n",
      "Index pair 41: [  5 106]\n",
      "Pair 42: 0.032087355852127075\n",
      "Index pair 42: [  5 107]\n",
      "Pair 43: -0.06603795289993286\n",
      "Index pair 43: [  5 108]\n",
      "Pair 44: -0.05739554762840271\n",
      "Index pair 44: [  5 109]\n",
      "Pair 45: -0.0594448447227478\n",
      "Index pair 45: [  5 110]\n",
      "Pair 46: -0.21235594153404236\n",
      "Index pair 46: [  5 111]\n",
      "Pair 47: -0.0302010178565979\n",
      "Index pair 47: [  5 112]\n",
      "Pair 48: 0.04163473844528198\n",
      "Index pair 48: [  5 113]\n",
      "Pair 49: 0.03839883208274841\n",
      "Index pair 49: [  5 114]\n",
      "Pair 50: -0.1901828944683075\n",
      "Index pair 50: [  5 115]\n",
      "Pair 51: -0.06050032377243042\n",
      "Index pair 51: [  5 116]\n",
      "Pair 52: 0.036007821559906006\n",
      "Index pair 52: [  5 117]\n",
      "Pair 53: -0.03159329295158386\n",
      "Index pair 53: [  5 118]\n",
      "Pair 54: -0.05491766333580017\n",
      "Index pair 54: [  5 119]\n",
      "Pair 55: -0.04199036955833435\n",
      "Index pair 55: [  5 120]\n",
      "Pair 56: -0.0025250911712646484\n",
      "Index pair 56: [  5 121]\n",
      "Pair 57: -0.1689300835132599\n",
      "Index pair 57: [  5 122]\n",
      "Pair 58: 0.06468865275382996\n",
      "Index pair 58: [  5 123]\n",
      "Pair 59: -0.0036476850509643555\n",
      "Index pair 59: [  5 124]\n",
      "Pair 60: 0.02217140793800354\n",
      "Index pair 60: [  5 125]\n",
      "Pair 61: -0.0758194625377655\n",
      "Index pair 61: [  5 126]\n",
      "Pair 62: -0.04448053240776062\n",
      "Index pair 62: [  5 127]\n",
      "Pair 63: -0.07362860441207886\n",
      "Index pair 63: [  5 128]\n",
      "Pair 64: -0.016525298357009888\n",
      "Index pair 64: [  5 129]\n",
      "Pair 65: -0.06362998485565186\n",
      "Index pair 65: [  5 130]\n",
      "Pair 66: 0.03769659996032715\n",
      "Index pair 66: [  5 131]\n",
      "Pair 67: -0.0050577521324157715\n",
      "Index pair 67: [  5 132]\n",
      "Pair 68: 0.056347042322158813\n",
      "Index pair 68: [  5 133]\n",
      "Pair 69: 0.04322618246078491\n",
      "Index pair 69: [  5 134]\n",
      "Pair 70: 0.01058804988861084\n",
      "Index pair 70: [  5 135]\n",
      "Pair 71: -0.06298103928565979\n",
      "Index pair 71: [  5 136]\n",
      "Pair 72: -0.03432956337928772\n",
      "Index pair 72: [  5 137]\n",
      "Pair 73: -0.11631119251251221\n",
      "Index pair 73: [  5 138]\n",
      "Pair 74: -0.10188266634941101\n",
      "Index pair 74: [  5 139]\n",
      "Pair 75: -0.0071367621421813965\n",
      "Index pair 75: [  5 140]\n",
      "Pair 76: -0.04889926314353943\n",
      "Index pair 76: [  5 141]\n",
      "Pair 77: 0.05414906144142151\n",
      "Index pair 77: [  5 142]\n",
      "Pair 78: -0.07351160049438477\n",
      "Index pair 78: [  5 143]\n",
      "Pair 79: -0.1471649706363678\n",
      "Index pair 79: [  5 144]\n",
      "Pair 80: 0.005404680967330933\n",
      "Index pair 80: [  5 145]\n",
      "Pair 81: 0.06222209334373474\n",
      "Index pair 81: [  5 146]\n",
      "Pair 82: -0.043972939252853394\n",
      "Index pair 82: [  5 147]\n",
      "Pair 83: -0.1248684823513031\n",
      "Index pair 83: [  5 148]\n",
      "Pair 84: -0.07468068599700928\n",
      "Index pair 84: [  5 149]\n",
      "Pair 85: -0.15001925826072693\n",
      "Index pair 85: [  5 150]\n",
      "Pair 86: -0.14894405007362366\n",
      "Index pair 86: [  5 151]\n",
      "Pair 87: -0.1088947057723999\n",
      "Index pair 87: [  5 152]\n",
      "Pair 88: -0.1607610285282135\n",
      "Index pair 88: [  5 153]\n",
      "Pair 89: -0.021700680255889893\n",
      "Index pair 89: [  5 154]\n",
      "Pair 90: -0.22978541254997253\n",
      "Index pair 90: [  5 155]\n",
      "Pair 91: -0.13625136017799377\n",
      "Index pair 91: [  5 156]\n",
      "Pair 92: -0.18313196301460266\n",
      "Index pair 92: [  5 157]\n",
      "Pair 93: -0.1217447817325592\n",
      "Index pair 93: [  5 158]\n",
      "Pair 94: -0.15775540471076965\n",
      "Index pair 94: [  5 159]\n",
      "Pair 95: -0.17733386158943176\n",
      "Index pair 95: [  5 160]\n",
      "Pair 96: -0.1417403519153595\n",
      "Index pair 96: [  5 161]\n",
      "Pair 97: -0.10894468426704407\n",
      "Index pair 97: [  5 162]\n",
      "Pair 98: -0.16049233078956604\n",
      "Index pair 98: [  5 163]\n",
      "Pair 99: 0.017847388982772827\n",
      "Index pair 99: [  5 164]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T21:07:06.537479100Z",
     "start_time": "2024-12-02T20:59:42.588199Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cf765a99750cda6e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
