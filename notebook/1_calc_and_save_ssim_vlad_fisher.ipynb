{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import libraries",
   "id": "50ea7da99a18c522"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-27T12:05:18.451943Z",
     "start_time": "2024-12-27T12:05:07.735604Z"
    }
   },
   "source": [
    "\n",
    "import re\n",
    "\n",
    "from src.utils import *\n",
    "from src.datasets import ExcavatorDataset\n",
    "from src.metrics import VLAD, FisherVector\n",
    "from scripts.evaluate import compute_and_save_ssim_matrices, compute_and_save_ssim_matrices_train_val\n",
    "from src.config import TRANSFORMER, ROOT"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STUD_VuNhat\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Die angegebene Prozedur wurde nicht gefunden'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "C:\\Users\\STUD_VuNhat\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T12:05:18.723896Z",
     "start_time": "2024-12-27T12:05:18.716868Z"
    }
   },
   "cell_type": "code",
   "source": "root = ROOT",
   "id": "6da1d41db0ca200c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T19:05:14.647948Z",
     "start_time": "2024-12-24T19:05:14.529886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "train_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='train')\n",
    "val_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='test')\n"
   ],
   "id": "252ce43dc92346d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\workspace\\similarity_metrics_of_images\\src\\datasets.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  key: torch.tensor(value / 255.0, dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load k-means and GMM models",
   "id": "f7e427ea78be16fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T13:42:41.440022Z",
     "start_time": "2024-12-12T13:42:41.425274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "k_means_models = [\n",
    "    model for model in os.listdir(rf'{root}/models/pickle_model_files') if 'k_means' in model\n",
    "]\n",
    "print(\"KMeans models:\", k_means_models)\n",
    "gmm_model = [\n",
    "    model for model in os.listdir(rf'{root}/models/pickle_model_files') if 'gmm' in model\n",
    "]\n",
    "print(\"GMM models:\", gmm_model)"
   ],
   "id": "f39dbc30a3e88125",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans models: ['k_means_model_k256_root_sift.pkl', 'k_means_model_k64_sift.pkl', 'k_means_model_k16_root_sift.pkl', 'k_means_model_k32_sift.pkl', 'k_means_model_k16_sift.pkl', 'k_means_model_k32_root_sift.pkl', 'k_means_model_k256_sift.pkl', 'k_means_model_k64_root_sift.pkl', 'k_means_model_k128_sift.pkl', 'k_means_model_k24_root_sift.pkl', 'k_means_model_k128_root_sift.pkl', 'k_means_model_k24_sift.pkl']\n",
      "GMM models: ['gmm_model_k32_sift.pkl', 'gmm_model_k256_sift.pkl', 'gmm_model_k256_root_sift.pkl', 'gmm_model_k64_root_sift.pkl', 'gmm_model_k16_root_sift.pkl', 'gmm_model_k24_sift.pkl', 'gmm_model_k24_root_sift.pkl', 'gmm_model_k64_sift.pkl', 'gmm_model_k32_root_sift.pkl', 'gmm_model_k16_sift.pkl', 'gmm_model_k128_root_sift.pkl', 'gmm_model_k128_sift.pkl']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compute and save VLAD vector matrix in `HD5` format",
   "id": "52cd18776958058a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T14:18:58.632385Z",
     "start_time": "2024-12-12T13:47:30.467728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(rf'{root}/res/vlad/train'):\n",
    "    os.makedirs(rf'{root}/res/vlad/train')\n",
    "\n",
    "if not os.path.exists(rf'{root}/res/vlad/validation'):\n",
    "    os.makedirs(rf'{root}/res/vlad/validation')\n",
    "\n",
    "for model in k_means_models:\n",
    "    num_clusters = int(re.findall(r'\\d+', model)[0])\n",
    "    vect_length = 128 * num_clusters if not 'pca' in model else 128 * num_clusters // 2\n",
    "    print(f\"Number of clusters: {num_clusters}, Vector length: {vect_length}\")\n",
    "    train_data = {}\n",
    "    val_data = {}\n",
    "    feature = 'root_sift' if 'root' in model else 'sift'\n",
    "    for img, *_, path in train_dataset:\n",
    "\n",
    "        vlad = VLAD(\n",
    "            image=img,\n",
    "            k_means=load_model(rf'{root}/models/pickle_model_files/{model}'),\n",
    "            flatten=True,\n",
    "            feature=feature\n",
    "        ).vector\n",
    "        if len(vlad) != vect_length:\n",
    "            raise ValueError(f\"Expected {vect_length}, got {len(vlad)}\")\n",
    "        path = os.path.basename(path)\n",
    "        train_data[path] = vlad\n",
    "\n",
    "    for img, *_, path in val_dataset:\n",
    "\n",
    "        vlad = VLAD(\n",
    "            image=img,\n",
    "            k_means=load_model(rf'{root}/models/pickle_model_files/{model}'),\n",
    "            flatten=True,\n",
    "            feature=feature\n",
    "        ).vector\n",
    "        if len(vlad) != vect_length:\n",
    "            raise ValueError(f\"Expected {vect_length}, got {len(vlad)}\")\n",
    "        path = os.path.basename(path)\n",
    "        val_data[path] = vlad\n",
    "\n",
    "    model_name = model.replace('.pkl', '')\n",
    "    save_to_hdf5(rf'{root}/res/vlad/train/{model_name}.h5', train_data)\n",
    "    save_to_hdf5(rf'{root}/res/vlad/validation/{model_name}.h5', val_data)"
   ],
   "id": "a13dbc56dc81e044",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 256, Vector length: 32768\n",
      "Number of clusters: 64, Vector length: 8192\n",
      "Number of clusters: 16, Vector length: 2048\n",
      "Number of clusters: 32, Vector length: 4096\n",
      "Number of clusters: 16, Vector length: 2048\n",
      "Number of clusters: 32, Vector length: 4096\n",
      "Number of clusters: 256, Vector length: 32768\n",
      "Number of clusters: 64, Vector length: 8192\n",
      "Number of clusters: 128, Vector length: 16384\n",
      "Number of clusters: 24, Vector length: 3072\n",
      "Number of clusters: 128, Vector length: 16384\n",
      "Number of clusters: 24, Vector length: 3072\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compute and save Fisher vector matrix in `HD5` format",
   "id": "18a6d20ce475b22c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T15:07:38.364114Z",
     "start_time": "2024-12-12T14:23:14.242783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(rf'{root}/res/fisher/train'):\n",
    "    os.makedirs(rf'{root}/res/fisher/train')\n",
    "\n",
    "if not os.path.exists(rf'{root}/res/fisher/validation'):\n",
    "    os.makedirs(rf'{root}/res/fisher/validation')\n",
    "\n",
    "for model in gmm_model:\n",
    "    num_clusters = int(re.findall(r'\\d+', model)[0])\n",
    "    vect_length = (2 * 128 * num_clusters + num_clusters) if not 'pca' in model else (\n",
    "                                                                                                 2 * 128 * num_clusters + num_clusters) // 2\n",
    "    print(f\"Number of clusters: {num_clusters}, Vector length: {vect_length}\")\n",
    "    train_data = {}\n",
    "    val_data = {}\n",
    "    feature = 'root_sift' if 'root' in model else 'sift'\n",
    "\n",
    "    for img, *_, path in train_dataset:\n",
    "\n",
    "        fisher = FisherVector(\n",
    "            image=img,\n",
    "            gmm=load_model(rf'{root}/models/pickle_model_files/{model}'),\n",
    "            flatten=True,\n",
    "            feature=feature\n",
    "        ).vector\n",
    "        if len(fisher) != vect_length:\n",
    "            raise ValueError(f\"Expected {vect_length}, got {len(fisher)}\")\n",
    "        path = os.path.basename(path)\n",
    "        train_data[path] = fisher\n",
    "\n",
    "    for img, *_, path in val_dataset:\n",
    "\n",
    "        fisher = FisherVector(\n",
    "            image=img,\n",
    "            gmm=load_model(rf'{root}/models/pickle_model_files/{model}'),\n",
    "            flatten=True,\n",
    "            feature=feature\n",
    "        ).vector\n",
    "        if len(fisher) != vect_length:\n",
    "            raise ValueError(f\"Expected {vect_length}, got {len(fisher)}\")\n",
    "        path = os.path.basename(path)\n",
    "        val_data[path] = fisher\n",
    "\n",
    "    model_name = model.replace('.pkl', '')\n",
    "    save_to_hdf5(rf'{root}/res/fisher/train/{model_name}.h5', train_data)\n",
    "    save_to_hdf5(rf'{root}/res/fisher/validation/{model_name}.h5', val_data)"
   ],
   "id": "62461d6f5a4b6d57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 32, Vector length: 8224\n",
      "Number of clusters: 256, Vector length: 65792\n",
      "Number of clusters: 256, Vector length: 65792\n",
      "Number of clusters: 64, Vector length: 16448\n",
      "Number of clusters: 16, Vector length: 4112\n",
      "Number of clusters: 24, Vector length: 6168\n",
      "Number of clusters: 24, Vector length: 6168\n",
      "Number of clusters: 64, Vector length: 16448\n",
      "Number of clusters: 32, Vector length: 8224\n",
      "Number of clusters: 16, Vector length: 4112\n",
      "Number of clusters: 128, Vector length: 32896\n",
      "Number of clusters: 128, Vector length: 32896\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SSIM\n",
    "\n",
    "1. Choosing kernel size for `gaussian_blur` function\n",
    "\n",
    "Using the empirical rule, the kernel radius should span 3 times the standard deviation. Which means:\n",
    "\n",
    "```python\n",
    "kernel_radius = int(3 * sigma)\n",
    "kernel_size = 2 * kernel_radius + 1 # In order that the kernel is centered around the central pixel\n",
    "```"
   ],
   "id": "76af4268817956e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T12:05:18.853149Z",
     "start_time": "2024-12-27T12:05:18.757841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='train', transform=TRANSFORMER)\n",
    "val_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='test', transform=TRANSFORMER)"
   ],
   "id": "63e8db1ddb00359a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## A) Compute SSIM Matrix within the dataset\n",
    "\n",
    "In the code below, the data is first saved as:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'image_paths': List[str],\n",
    "    'ssim': np.ndarray,\n",
    "    'ms_ssim': np.ndarray\n",
    "}\n",
    "```\n",
    "because of computational constraints (could takr up to 16 hours/iteration)."
   ],
   "id": "b959ba99d40bb635"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-24T19:06:16.223845Z",
     "start_time": "2024-12-24T19:05:52.806845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = f'{root}/res/ssim/within_train'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "batch_size = 20\n",
    "gaussian_sigmas = [i for i in range(0, 12, 2)]  # [0, 2, 4, 6, 8, 10]\n",
    "\n",
    "for sigma in gaussian_sigmas:\n",
    "    compute_and_save_ssim_matrices(dataset=train_dataset,\n",
    "                                   output_dir=output_dir,\n",
    "                                   batch_size=batch_size,\n",
    "                                   sigma=sigma)"
   ],
   "id": "a7e17318ea676a7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel size used for sigma=4: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STUD_VuNhat\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m gaussian_sigmas \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m2\u001B[39m)]  \u001B[38;5;66;03m# [0, 2, 4, 6, 8, 10]\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sigma \u001B[38;5;129;01min\u001B[39;00m gaussian_sigmas:\n\u001B[1;32m----> 9\u001B[0m     compute_and_save_ssim_matrices(dataset\u001B[38;5;241m=\u001B[39mtrain_dataset,\n\u001B[0;32m     10\u001B[0m                                    output_dir\u001B[38;5;241m=\u001B[39moutput_dir,\n\u001B[0;32m     11\u001B[0m                                    batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     12\u001B[0m                                    sigma\u001B[38;5;241m=\u001B[39msigma)\n",
      "File \u001B[1;32mC:\\workspace\\similarity_metrics_of_images\\src\\evaluate.py:251\u001B[0m, in \u001B[0;36mcompute_and_save_ssim_matrices\u001B[1;34m(dataset, output_dir, batch_size, sigma, compression_quality)\u001B[0m\n\u001B[0;32m    248\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m new_transforms\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKernel size used for sigma=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msigma\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkernel_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 251\u001B[0m images \u001B[38;5;241m=\u001B[39m [image_array \u001B[38;5;28;01mfor\u001B[39;00m image_array, \u001B[38;5;241m*\u001B[39m_ \u001B[38;5;129;01min\u001B[39;00m dataset]\n\u001B[0;32m    252\u001B[0m image_paths \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(path) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;241m*\u001B[39m_, path \u001B[38;5;129;01min\u001B[39;00m dataset]\n\u001B[0;32m    253\u001B[0m images \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(images, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\workspace\\similarity_metrics_of_images\\src\\evaluate.py:251\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    248\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m new_transforms\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKernel size used for sigma=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msigma\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkernel_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 251\u001B[0m images \u001B[38;5;241m=\u001B[39m [image_array \u001B[38;5;28;01mfor\u001B[39;00m image_array, \u001B[38;5;241m*\u001B[39m_ \u001B[38;5;129;01min\u001B[39;00m dataset]\n\u001B[0;32m    252\u001B[0m image_paths \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(path) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;241m*\u001B[39m_, path \u001B[38;5;129;01min\u001B[39;00m dataset]\n\u001B[0;32m    253\u001B[0m images \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(images, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\workspace\\similarity_metrics_of_images\\src\\datasets.py:220\u001B[0m, in \u001B[0;36mBaseDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[0;32m    219\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform, transforms\u001B[38;5;241m.\u001B[39mCompose):\n\u001B[1;32m--> 220\u001B[0m         image_array \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image_array)\n\u001B[0;32m    221\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    222\u001B[0m             mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(mask)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m t(img)\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:361\u001B[0m, in \u001B[0;36mResize.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m    354\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    355\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    356\u001B[0m \u001B[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    359\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mresize(img, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msize, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterpolation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mantialias)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torchvision\\transforms\\functional.py:492\u001B[0m, in \u001B[0;36mresize\u001B[1;34m(img, size, interpolation, max_size, antialias)\u001B[0m\n\u001B[0;32m    489\u001B[0m     pil_interpolation \u001B[38;5;241m=\u001B[39m pil_modes_mapping[interpolation]\n\u001B[0;32m    490\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F_pil\u001B[38;5;241m.\u001B[39mresize(img, size\u001B[38;5;241m=\u001B[39moutput_size, interpolation\u001B[38;5;241m=\u001B[39mpil_interpolation)\n\u001B[1;32m--> 492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mresize(img, size\u001B[38;5;241m=\u001B[39moutput_size, interpolation\u001B[38;5;241m=\u001B[39minterpolation\u001B[38;5;241m.\u001B[39mvalue, antialias\u001B[38;5;241m=\u001B[39mantialias)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:467\u001B[0m, in \u001B[0;36mresize\u001B[1;34m(img, size, interpolation, antialias)\u001B[0m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;66;03m# Define align_corners to avoid warnings\u001B[39;00m\n\u001B[0;32m    465\u001B[0m align_corners \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m interpolation \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 467\u001B[0m img \u001B[38;5;241m=\u001B[39m interpolate(img, size\u001B[38;5;241m=\u001B[39msize, mode\u001B[38;5;241m=\u001B[39minterpolation, align_corners\u001B[38;5;241m=\u001B[39malign_corners, antialias\u001B[38;5;241m=\u001B[39mantialias)\n\u001B[0;32m    469\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m interpolation \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbicubic\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m out_dtype \u001B[38;5;241m==\u001B[39m torch\u001B[38;5;241m.\u001B[39muint8:\n\u001B[0;32m    470\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mclamp(\u001B[38;5;28mmin\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mmax\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m255\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\torch\\nn\\functional.py:4580\u001B[0m, in \u001B[0;36minterpolate\u001B[1;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001B[0m\n\u001B[0;32m   4571\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mare_deterministic_algorithms_enabled() \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m   4572\u001B[0m             \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mis_cuda \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mis_xpu\n\u001B[0;32m   4573\u001B[0m         ):\n\u001B[0;32m   4574\u001B[0m             \u001B[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001B[39;00m\n\u001B[0;32m   4575\u001B[0m             \u001B[38;5;66;03m# importlib is required because the import cannot be top level\u001B[39;00m\n\u001B[0;32m   4576\u001B[0m             \u001B[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001B[39;00m\n\u001B[0;32m   4577\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\n\u001B[0;32m   4578\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch._decomp.decompositions\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   4579\u001B[0m             )\u001B[38;5;241m.\u001B[39m_upsample_linear_vec(\u001B[38;5;28minput\u001B[39m, output_size, align_corners, scale_factors)\n\u001B[1;32m-> 4580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_nn\u001B[38;5;241m.\u001B[39mupsample_bilinear2d(\n\u001B[0;32m   4581\u001B[0m         \u001B[38;5;28minput\u001B[39m, output_size, align_corners, scale_factors\n\u001B[0;32m   4582\u001B[0m     )\n\u001B[0;32m   4583\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrilinear\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   4584\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m align_corners \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## B) Compute SSIM Matrix between train and validation datasets",
   "id": "dc8c101bbac356a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T16:56:01.798566Z",
     "start_time": "2024-12-25T13:45:11.540291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = f'{root}/res/ssim/train_vs_val'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 20\n",
    "gaussian_sigmas = [i for i in range(0, 12, 2)]  # [0, 2, 4, 6, 8, 10]\n",
    "for sigma in gaussian_sigmas:\n",
    "    compute_and_save_ssim_matrices_train_val(train_dataset=train_dataset, # TODO: Fix this method (it currently creates too large files)\n",
    "                                             val_dataset=val_dataset,\n",
    "                                             output_dir=output_dir,\n",
    "                                             batch_size=batch_size,\n",
    "                                             sigma=sigma)\n",
    "\n"
   ],
   "id": "131baef845dc4cb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ssim and ms_ssim with sigma=4 for all pairs (val vs train).\n",
      "Kernel size used for sigma = 4: 25\n",
      "Transformer used: Compose(\n",
      "    ToTensor()\n",
      "    Resize(size=(640, 640), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    GaussianBlur(kernel_size=(25, 25), sigma=(4, 4))\n",
      ")\n",
      "All validation paths loaded.\n",
      "All training paths loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing SSIM/MS-SSIM (val vs train): 100%|██████████| 187/187 [3:09:52<00:00, 60.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train-val SSIM and MS-SSIM matrices at C:\\workspace\\similarity_metrics_of_images/res/ssim/train_vs_val with sigma=4, kernel_size=25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# C) B, but with grayscale images",
   "id": "2607d96d2f5c9dc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T11:53:16.935820Z",
     "start_time": "2024-12-27T11:53:14.566329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dir = f'{root}/res/ssim/train_vs_val/grayscale'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 20\n",
    "gaussian_sigmas = [i for i in range(0, 12, 2)]  # [0, 2, 4, 6, 8, 10]\n",
    "for sigma in gaussian_sigmas:\n",
    "    compute_and_save_ssim_matrices_train_val(train_dataset=train_dataset,\n",
    "                                             val_dataset=val_dataset,\n",
    "                                             output_dir=output_dir,\n",
    "                                             grayscale=True,\n",
    "                                             batch_size=batch_size,\n",
    "                                             sigma=sigma)"
   ],
   "id": "44ac63abf38da598",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-27 12:53:14,572 - root - INFO - Training dataset initialized.\n",
      "2024-12-27 12:53:14,574 - root - INFO - Test dataset initialized.\n",
      "Computing ssim and ms_ssim with sigma=0 for all pairs (val vs train).\n",
      "2024-12-27 12:53:14,604 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,619 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,641 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,651 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,671 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,681 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,698 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,708 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,728 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,738 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,755 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,765 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,781 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,791 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,808 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,819 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,837 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,847 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,865 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,876 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,893 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,904 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,921 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,932 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,949 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,959 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:14,976 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:14,986 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,003 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,013 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,032 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,042 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,059 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,068 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,086 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,096 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,115 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,125 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,143 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,153 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,171 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,181 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,199 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,209 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,227 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,238 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,255 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,264 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,284 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,294 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,313 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,324 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,341 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,351 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,371 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,381 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,398 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,407 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,422 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,432 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,449 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,459 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,474 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,484 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,502 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,512 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,529 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,539 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,557 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,567 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,584 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,594 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,612 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,622 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,640 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,650 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,668 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,678 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,694 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,704 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,721 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,731 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,747 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,758 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,775 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,785 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,804 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,814 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,832 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,843 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,859 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,869 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n",
      "2024-12-27 12:53:15,885 - ExcavatorDataset - INFO - RGB mask detected with shape: torch.Size([3, 640, 640]). Converting to class mask.\n",
      "2024-12-27 12:53:15,893 - ExcavatorDataset - INFO - Mask converted with new shape: torch.Size([640, 640])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m gaussian_sigmas \u001B[38;5;241m=\u001B[39m [i \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m2\u001B[39m)]  \u001B[38;5;66;03m# [0, 2, 4, 6, 8, 10]\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sigma \u001B[38;5;129;01min\u001B[39;00m gaussian_sigmas:\n\u001B[1;32m----> 8\u001B[0m     compute_and_save_ssim_matrices_train_val(output_dir\u001B[38;5;241m=\u001B[39moutput_dir,\n\u001B[0;32m      9\u001B[0m                                              batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     10\u001B[0m                                             grayscale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     11\u001B[0m                                              sigma\u001B[38;5;241m=\u001B[39msigma)\n",
      "File \u001B[1;32mC:\\workspace\\similarity_metrics_of_images\\scripts\\evaluate.py:429\u001B[0m, in \u001B[0;36mcompute_and_save_ssim_matrices_train_val\u001B[1;34m(output_dir, between, grayscale, sigma, batch_size, verbose)\u001B[0m\n\u001B[0;32m    426\u001B[0m num_dset1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset_1)\n\u001B[0;32m    427\u001B[0m num_dset2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset_2)\n\u001B[1;32m--> 429\u001B[0m all_paths_1 \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(path) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;241m*\u001B[39m_, path \u001B[38;5;129;01min\u001B[39;00m dataset_1]\n\u001B[0;32m    430\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll validation paths loaded.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    431\u001B[0m all_paths_2 \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(path) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;241m*\u001B[39m_, path \u001B[38;5;129;01min\u001B[39;00m dataset_2]\n",
      "File \u001B[1;32mC:\\workspace\\similarity_metrics_of_images\\scripts\\evaluate.py:429\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    426\u001B[0m num_dset1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset_1)\n\u001B[0;32m    427\u001B[0m num_dset2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataset_2)\n\u001B[1;32m--> 429\u001B[0m all_paths_1 \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(path) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;241m*\u001B[39m_, path \u001B[38;5;129;01min\u001B[39;00m dataset_1]\n\u001B[0;32m    430\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll validation paths loaded.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    431\u001B[0m all_paths_2 \u001B[38;5;241m=\u001B[39m [os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(path) \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;241m*\u001B[39m_, path \u001B[38;5;129;01min\u001B[39;00m dataset_2]\n",
      "File \u001B[1;32mC:\\workspace\\similarity_metrics_of_images\\src\\datasets.py:218\u001B[0m, in \u001B[0;36mBaseDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    216\u001B[0m         mask \u001B[38;5;241m=\u001B[39m permute_image_channels(mask)\n\u001B[0;32m    217\u001B[0m     mask \u001B[38;5;241m=\u001B[39m rgb_to_mask(mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_colors)\n\u001B[1;32m--> 218\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMask converted with new shape: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, mask\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mone_hot_encode_mask:\n\u001B[0;32m    220\u001B[0m     mask \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mone_hot(mask\u001B[38;5;241m.\u001B[39mlong(), num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:1489\u001B[0m, in \u001B[0;36mLogger.info\u001B[1;34m(self, msg, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1480\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1481\u001B[0m \u001B[38;5;124;03mLog 'msg % args' with severity 'INFO'.\u001B[39;00m\n\u001B[0;32m   1482\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1486\u001B[0m \u001B[38;5;124;03mlogger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=True)\u001B[39;00m\n\u001B[0;32m   1487\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39misEnabledFor(INFO):\n\u001B[1;32m-> 1489\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_log(INFO, msg, args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:1634\u001B[0m, in \u001B[0;36mLogger._log\u001B[1;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001B[0m\n\u001B[0;32m   1631\u001B[0m         exc_info \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mexc_info()\n\u001B[0;32m   1632\u001B[0m record \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakeRecord(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, level, fn, lno, msg, args,\n\u001B[0;32m   1633\u001B[0m                          exc_info, func, extra, sinfo)\n\u001B[1;32m-> 1634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle(record)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:1644\u001B[0m, in \u001B[0;36mLogger.handle\u001B[1;34m(self, record)\u001B[0m\n\u001B[0;32m   1637\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1638\u001B[0m \u001B[38;5;124;03mCall the handlers for the specified record.\u001B[39;00m\n\u001B[0;32m   1639\u001B[0m \n\u001B[0;32m   1640\u001B[0m \u001B[38;5;124;03mThis method is used for unpickled records received from a socket, as\u001B[39;00m\n\u001B[0;32m   1641\u001B[0m \u001B[38;5;124;03mwell as those created locally. Logger-level filtering is applied.\u001B[39;00m\n\u001B[0;32m   1642\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1643\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisabled) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilter(record):\n\u001B[1;32m-> 1644\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallHandlers(record)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:1706\u001B[0m, in \u001B[0;36mLogger.callHandlers\u001B[1;34m(self, record)\u001B[0m\n\u001B[0;32m   1704\u001B[0m     found \u001B[38;5;241m=\u001B[39m found \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1705\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m record\u001B[38;5;241m.\u001B[39mlevelno \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m hdlr\u001B[38;5;241m.\u001B[39mlevel:\n\u001B[1;32m-> 1706\u001B[0m         hdlr\u001B[38;5;241m.\u001B[39mhandle(record)\n\u001B[0;32m   1707\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m c\u001B[38;5;241m.\u001B[39mpropagate:\n\u001B[0;32m   1708\u001B[0m     c \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m    \u001B[38;5;66;03m#break out\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:978\u001B[0m, in \u001B[0;36mHandler.handle\u001B[1;34m(self, record)\u001B[0m\n\u001B[0;32m    976\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39macquire()\n\u001B[0;32m    977\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 978\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39memit(record)\n\u001B[0;32m    979\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    980\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:1114\u001B[0m, in \u001B[0;36mStreamHandler.emit\u001B[1;34m(self, record)\u001B[0m\n\u001B[0;32m   1112\u001B[0m     \u001B[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001B[39;00m\n\u001B[0;32m   1113\u001B[0m     stream\u001B[38;5;241m.\u001B[39mwrite(msg \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mterminator)\n\u001B[1;32m-> 1114\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflush()\n\u001B[0;32m   1115\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRecursionError\u001B[39;00m:  \u001B[38;5;66;03m# See issue 36272\u001B[39;00m\n\u001B[0;32m   1116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\logging\\__init__.py:1094\u001B[0m, in \u001B[0;36mStreamHandler.flush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mflush\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1094\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream\u001B[38;5;241m.\u001B[39mflush()\n\u001B[0;32m   1095\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1096\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\site-packages\\ipykernel\\iostream.py:578\u001B[0m, in \u001B[0;36mOutStream.flush\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    576\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_thread\u001B[38;5;241m.\u001B[39mschedule(evt\u001B[38;5;241m.\u001B[39mset)\n\u001B[0;32m    577\u001B[0m     \u001B[38;5;66;03m# and give a timeout to avoid\u001B[39;00m\n\u001B[1;32m--> 578\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt\u001B[38;5;241m.\u001B[39mwait(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflush_timeout):\n\u001B[0;32m    579\u001B[0m         \u001B[38;5;66;03m# write directly to __stderr__ instead of warning because\u001B[39;00m\n\u001B[0;32m    580\u001B[0m         \u001B[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001B[39;00m\n\u001B[0;32m    581\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIOStream.flush timed out\u001B[39m\u001B[38;5;124m\"\u001B[39m, file\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39m__stderr__)\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\threading.py:629\u001B[0m, in \u001B[0;36mEvent.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    627\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[1;32m--> 629\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cond\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\conda_env\\Lib\\threading.py:331\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 331\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mTrue\u001B[39;00m, timeout)\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    333\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
