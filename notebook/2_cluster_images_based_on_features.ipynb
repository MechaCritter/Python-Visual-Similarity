{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#  Import libraries",
   "id": "72e237d2f1068b71"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T20:05:11.555656Z",
     "start_time": "2024-12-07T20:05:11.543913Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Use Agg backend to save figures\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "from src.utils import *\n",
    "from src.datasets import ExcavatorDataset\n",
    "from src.metrics import VLAD, FisherVector\n",
    "from src.config import ROOT"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "root = ROOT",
   "id": "5160cd05b0fcf973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cluster images based on their VLAD/Fisher vectors (DONE)",
   "id": "66113a295ff664d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.utils import *\n",
    "import tqdm\n",
    "\n",
    "k_means_models = ['k_means_model_k32_sift', 'k_means_model_k32_root_sift', 'k_means_model_k64_root_sift', 'k_means_model_k64_sift', 'k_means_model_k128_root_sift', 'k_means_model_k128_sift', 'k_means_model_k256_sift', 'k_means_model_k256_root_sift']\n",
    "\n",
    "\n",
    "vectors_dir = f'{root}/res/vlad'\n",
    "output_dir = f'{root}/res/similarity_matrix'\n",
    "\n",
    "for num_clusters in range(20, 61, 5):\n",
    "    for model in k_means_models:\n",
    "        kmeans_h5_paths = f'{root}/res/vlad/{model}.h5'\n",
    "\n",
    "        data = load_hdf5(f'{root}/res/vlad/{model}.h5')\n",
    "        image_paths = list(data.keys())\n",
    "        vectors = np.array([data[path] for path in image_paths])\n",
    "        image_paths = [path.replace('|', '/') for path in image_paths]\n",
    "        cluster_images_and_save(image_paths,\n",
    "                                vectors,\n",
    "                                n_clusters=num_clusters,\n",
    "                                output_dir=f'{root}/res/clustered_datasets_{num_clusters}_clusters/vlad/{model}')"
   ],
   "id": "89ffd51ff07c91a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cluster images based on their Fisher vectors (DONE)",
   "id": "3217421223763e92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gmm_models = ['gmm_model_k32_sift',  'gmm_model_k32_root_sift', 'gmm_model_k64_root_sift', 'gmm_model_k64_sift', 'gmm_model_k128_root_sift', 'gmm_model_k128_sift', 'gmm_model_k256_sift', 'gmm_model_k256_root_sift']\n",
    "\n",
    "vectors_dir = f'{root}/res/fisher'\n",
    "output_dir = f'{root}/res/similarity_matrix'\n",
    "\n",
    "for num_clusters in range(20, 61, 5):\n",
    "    for model in gmm_models:\n",
    "        gmm_h5_paths = f'{root}/res/fisher/{model}.h5'\n",
    "\n",
    "        data = load_hdf5(f'{root}/res/fisher/{model}.h5')\n",
    "        image_paths = list(data.keys())\n",
    "        vectors = np.array([data[path] for path in image_paths])\n",
    "        image_paths = [path.replace('|', '/') for path in image_paths]\n",
    "        cluster_images_and_save(image_paths,\n",
    "                                vectors,\n",
    "                                n_clusters=num_clusters,\n",
    "                                output_dir=f'{root}/res/clustered_datasets_{num_clusters}_clusters/fisher/{model}')"
   ],
   "id": "49a6bbffa28d44e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate overall similarity within each cluster",
   "id": "d91f83d6f5d81916"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def create_and_save_boxplots_per_model(\n",
    "    models_data: dict[str, dict[int, list[float]]],\n",
    "    x_label: str = \"Number of Clusters\",\n",
    "    y_label: str = \"Average Similarity Score\",\n",
    "    show: bool = True,\n",
    "    save_fig_path: str = None,\n",
    "    plots_per_row: int = 4,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create and save boxplots for each model, arranged in subplots with the same y-axis scale.\n",
    "\n",
    "    :param models_data: dict where keys are model names, values are dicts of {number of clusters: list of values}\n",
    "    :param x_label: Label for x-axis\n",
    "    :param y_label: Label for y-axis\n",
    "    :param show: Whether to display the plot\n",
    "    :param save_fig_path: Path to save the figure\n",
    "    :param plots_per_row: Number of plots per row\n",
    "    \"\"\"\n",
    "    num_models = len(models_data)\n",
    "    num_rows = (num_models + plots_per_row - 1) // plots_per_row  # Ceiling division\n",
    "    fig, axes = plt.subplots(\n",
    "        num_rows, plots_per_row, figsize=(plots_per_row * 5, num_rows * 5)\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Compute global y-axis limits\n",
    "    all_values = [value for data_dict in models_data.values() for values in data_dict.values() for value in values]\n",
    "    global_y_min, global_y_max = min(all_values), max(all_values)\n",
    "\n",
    "    for idx, (model, data_dict) in enumerate(models_data.items()):\n",
    "        ax = axes[idx]\n",
    "        x_values = sorted(data_dict.keys())\n",
    "        data = [data_dict[x] for x in x_values]\n",
    "        # Create boxplot\n",
    "        _ = ax.boxplot(data, positions=range(len(x_values)), patch_artist=True)\n",
    "        # Set x-ticks to x_values\n",
    "        ax.set_xticks(range(len(x_values)))\n",
    "        ax.set_xticklabels(x_values)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.set_title(model)\n",
    "        ax.set_ylim(global_y_min, global_y_max)  # Apply global y-axis limits\n",
    "        # Compute mean average similarity scores for regression\n",
    "        mean_values = [np.mean(data_dict[x]) for x in x_values]\n",
    "        # Fit regression line\n",
    "        slope, intercept, _, _, _ = linregress(x_values, mean_values)\n",
    "        # Compute regression line values\n",
    "        reg_line = [slope * x + intercept for x in x_values]\n",
    "        # Plot regression line\n",
    "        ax.plot(range(len(x_values)), reg_line, color=\"red\", linestyle=\"--\", label=f\"Slope: {slope:.2f}-Intercept: {intercept:.2f}\")\n",
    "        ax.legend()\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for idx in range(num_models, num_rows * plots_per_row):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_fig_path:\n",
    "        plt.savefig(save_fig_path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "k_means_models = ['k_means_model_k32_sift', 'k_means_model_k32_root_sift', 'k_means_model_k64_root_sift', 'k_means_model_k64_sift', 'k_means_model_k128_root_sift', 'k_means_model_k128_sift', 'k_means_model_k256_sift', 'k_means_model_k256_root_sift']\n",
    "\n",
    "vlad_models_data = {}\n",
    "\n",
    "for model in k_means_models:\n",
    "    print(\"Processing model:\", model)\n",
    "    vlad_models_data[model] = {}\n",
    "    for num_clusters in range(20, 61, 5):\n",
    "        vlad_models_data[model][num_clusters] = []\n",
    "        cluster_dir = f'{root}/res/clustered_datasets_{num_clusters}_clusters/vlad/{model}'\n",
    "        print(\"Cluster dir:\", cluster_dir)\n",
    "\n",
    "        if os.path.exists(cluster_dir):\n",
    "            for cluster_subdir in os.listdir(cluster_dir):\n",
    "                cluster_subdir_path = os.path.join(cluster_dir, cluster_subdir)\n",
    "                if os.path.isdir(cluster_subdir_path):\n",
    "                    json_file_path = os.path.join(cluster_subdir_path, f'{cluster_subdir}_info.json')\n",
    "                    if os.path.exists(json_file_path):\n",
    "                        with open(json_file_path, 'r') as f:\n",
    "                            data_json = json.load(f)\n",
    "                            avg_similarity = data_json.get('average_similarity')\n",
    "                            num_images = len([file for file in os.listdir(cluster_subdir_path) if file.lower().endswith('.jpg')])\n",
    "\n",
    "                            if avg_similarity is not None:\n",
    "                                vlad_models_data[model][num_clusters].append(avg_similarity)\n",
    "# Sort data based on number of clusters\n",
    "\n",
    "\n",
    "# Now create the boxplots\n",
    "create_and_save_boxplots_per_model(\n",
    "    vlad_models_data,\n",
    "    x_label=\"Number of Image Clusters\",\n",
    "    y_label=\"Average Similarity Score\",\n",
    "    show=True,\n",
    "    save_fig_path='res/average_similarity_boxplots.png',\n",
    "    plots_per_row=4\n",
    ")\n"
   ],
   "id": "39f9ef41f765db53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gmm_models = ['gmm_model_k32_sift',  'gmm_model_k32_root_sift', 'gmm_model_k64_root_sift', 'gmm_model_k64_sift', 'gmm_model_k128_root_sift', 'gmm_model_k128_sift', 'gmm_model_k256_sift', 'gmm_model_k256_root_sift']\n",
    "\n",
    "gmm_models_data = {}\n",
    "\n",
    "for model in gmm_models:\n",
    "    print(\"Processing model:\", model)\n",
    "    gmm_models_data[model] = {}\n",
    "    for num_clusters in range(20, 61, 5):\n",
    "        gmm_models_data[model][num_clusters] = []\n",
    "        cluster_dir = f'{root}/res/clustered_datasets_{num_clusters}_clusters/fisher/{model}'\n",
    "        print(\"Cluster dir:\", cluster_dir)\n",
    "\n",
    "        if os.path.exists(cluster_dir):\n",
    "            for cluster_subdir in os.listdir(cluster_dir):\n",
    "                cluster_subdir_path = os.path.join(cluster_dir, cluster_subdir)\n",
    "                if os.path.isdir(cluster_subdir_path):\n",
    "                    json_file_path = os.path.join(cluster_subdir_path, f'{cluster_subdir}_info.json')\n",
    "                    if os.path.exists(json_file_path):\n",
    "                        with open(json_file_path, 'r') as f:\n",
    "                            data_json = json.load(f)\n",
    "                            avg_similarity = data_json.get('average_similarity')\n",
    "                            num_images = len([file for file in os.listdir(cluster_subdir_path) if file.lower().endswith('.jpg')])\n",
    "\n",
    "                            if avg_similarity is not None:\n",
    "                                gmm_models_data[model][num_clusters].append(avg_similarity)\n",
    "\n",
    "# Now create the boxplots\n",
    "create_and_save_boxplots_per_model(\n",
    "    gmm_models_data,\n",
    "    x_label=\"Number of Image Clusters\",\n",
    "    y_label=\"Average Similarity Score\",\n",
    "    show=True,\n",
    "    save_fig_path='res/average_similarity_boxplots.png',\n",
    "    plots_per_row=4\n",
    ")\n"
   ],
   "id": "b23c6c1a0d7d182",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ab38073d1892e4ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
