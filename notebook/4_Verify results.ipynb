{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c6d737d119a30c",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:51:47.608987Z",
     "start_time": "2024-12-23T08:51:47.599847Z"
    }
   },
   "source": [
    "import torch\n",
    "from piq import ssim, multi_scale_ssim as ms_ssim\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "from src.metrics import *\n",
    "from src.utils import *\n",
    "from src.datasets import ExcavatorDataset\n",
    "from src.config import TRANSFORMER, ROOT, DEVICE\n",
    "from models.Segmentation import DeepLabV3Model, DeepLabV3PlusModel, PyramidAttentionNetworkModel, UNetModel"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load dataset",
   "id": "ad580c94d02c290e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:19:01.210104Z",
     "start_time": "2024-12-23T08:19:01.192357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='train', plot=False)\n",
    "print(\"Number of train imgs: \", len(train_dataset))\n",
    "test_dataset = ExcavatorDataset(return_type='image+mask+path', purpose='test', plot=False)\n",
    "print(\"Number of val imgs: \", len(test_dataset))\n",
    "cls_colors = train_dataset.class_colors"
   ],
   "id": "97071f807339833a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train imgs:  1782\n",
      "Number of val imgs:  187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ais/Bachelorarbeit/similarity_metrics_of_images/src/datasets.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  key: torch.tensor(value / 255.0, dtype=torch.float32)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "9a76c70c4aa17e63",
   "metadata": {},
   "source": [
    "# Test 1. VLAD (PASS)"
   ]
  },
  {
   "cell_type": "code",
   "id": "bef8ea8c7002844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:35:48.391636Z",
     "start_time": "2024-12-17T15:35:16.933522Z"
    }
   },
   "source": [
    "for i in range(30):\n",
    "    num_cls= np.random.choice([32, 64, 128, 256])\n",
    "    feature = np.random.choice(['sift', 'root_sift'])\n",
    "    dataset_choice = np.random.choice(['train', 'validation'])\n",
    "    if dataset_choice == 'train':\n",
    "        dataset = train_dataset\n",
    "    else:\n",
    "        dataset = test_dataset\n",
    "    print(\"Chosen dataset:\", dataset_choice)\n",
    "    idx_1 = 0\n",
    "    idx_2 = 0\n",
    "    while idx_1 == idx_2:\n",
    "        idx_1 = random.randint(0, len(dataset)-1)\n",
    "        idx_2 = random.randint(0, len(dataset)-1)\n",
    "\n",
    "    image_1, *_ ,path1= dataset[idx_1]\n",
    "    image_2, *_, path2 = dataset[idx_2]\n",
    "    k_means = load_model(f'{ROOT}/models/pickle_model_files/k_means_model_k{num_cls}_{feature}.pkl')\n",
    "\n",
    "    vlad_1 = VLAD(image_1, k_means=k_means, flatten=True, feature=feature, verbose=False).vector\n",
    "    print(\"Length of VLAD vector:\", len(vlad_1))\n",
    "    vlad_2 = VLAD(image_2, k_means=k_means, flatten=True, feature=feature, verbose=False).vector\n",
    "    print(\"Length of VLAD vector:\", len(vlad_2))\n",
    "\n",
    "    print(\"VLAD cosine similarity:\", res:=cosine_similarity(vlad_1.reshape(1, -1), vlad_2.reshape(1, -1))[0][0])\n",
    "\n",
    "    hdf_file = load_hdf5(f'{ROOT}/res/vlad/{dataset_choice}/k_means_model_k{num_cls}_{feature}.h5')\n",
    "\n",
    "    vlad_check_1 = hdf_file[os.path.basename(path1)]\n",
    "    vlad_check_2 = hdf_file[os.path.basename(path2)]\n",
    "    print(\"Check VLAD cosine similarity:\", res_check:=cosine_similarity(vlad_check_1.reshape(1, -1), vlad_check_2.reshape(1, -1))[0][0])\n",
    "    if not abs(res - res_check) < 1e-5:\n",
    "        raise ValueError(\"VLAD cosine similarity is not equal to the check value\")\n",
    "\n",
    "print(\"Test passed\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen dataset: train\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: 0.02222677560055967\n",
      "Check VLAD cosine similarity: 0.02222677560055967\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: 0.025105189288985058\n",
      "Check VLAD cosine similarity: 0.025105189288985058\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: -0.15603733185873025\n",
      "Check VLAD cosine similarity: -0.15603733185873025\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: 0.06508906291638653\n",
      "Check VLAD cosine similarity: 0.06508906291638653\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: 0.0012902705248705468\n",
      "Check VLAD cosine similarity: 0.0012902705248705468\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: 0.01370333261744806\n",
      "Check VLAD cosine similarity: 0.01370333261744806\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 8192\n",
      "Length of VLAD vector: 8192\n",
      "VLAD cosine similarity: 0.033739928944456196\n",
      "Check VLAD cosine similarity: 0.033739928944456196\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: 0.003535443533919154\n",
      "Check VLAD cosine similarity: 0.003535443533919154\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: -0.026983166033137992\n",
      "Check VLAD cosine similarity: -0.026983166033137992\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: -0.037426432059306236\n",
      "Check VLAD cosine similarity: -0.037426432059306236\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: 0.13088607998816754\n",
      "Check VLAD cosine similarity: 0.13088607998816754\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: -0.041158395450832275\n",
      "Check VLAD cosine similarity: -0.041158395450832275\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: 0.0718445831808988\n",
      "Check VLAD cosine similarity: 0.0718445831808988\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: 0.05593630023633854\n",
      "Check VLAD cosine similarity: 0.05593630023633854\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: -0.08636076314672264\n",
      "Check VLAD cosine similarity: -0.08636076314672264\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 8192\n",
      "Length of VLAD vector: 8192\n",
      "VLAD cosine similarity: 0.04833240582268122\n",
      "Check VLAD cosine similarity: 0.04833240582268122\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 8192\n",
      "Length of VLAD vector: 8192\n",
      "VLAD cosine similarity: -0.045172073890654404\n",
      "Check VLAD cosine similarity: -0.045172073890654404\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 8192\n",
      "Length of VLAD vector: 8192\n",
      "VLAD cosine similarity: 0.06131326190125911\n",
      "Check VLAD cosine similarity: 0.06131326190125911\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: 0.05652554011824437\n",
      "Check VLAD cosine similarity: 0.05652554011824437\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: -0.045628653112382137\n",
      "Check VLAD cosine similarity: -0.045628653112382137\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: 0.015407730285141877\n",
      "Check VLAD cosine similarity: 0.015407730285141877\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: 0.06271314785735302\n",
      "Check VLAD cosine similarity: 0.06271314785735302\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8192\n",
      "Length of VLAD vector: 8192\n",
      "VLAD cosine similarity: 0.08495314899656532\n",
      "Check VLAD cosine similarity: 0.08495314899656532\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 16384\n",
      "Length of VLAD vector: 16384\n",
      "VLAD cosine similarity: 0.06557410474590902\n",
      "Check VLAD cosine similarity: 0.06557410474590902\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: -0.03847951344046391\n",
      "Check VLAD cosine similarity: -0.03847951344046391\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8192\n",
      "Length of VLAD vector: 8192\n",
      "VLAD cosine similarity: -0.020347332663844295\n",
      "Check VLAD cosine similarity: -0.020347332663844295\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: -0.0077954190100006995\n",
      "Check VLAD cosine similarity: -0.0077954190100006995\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: -0.06347357354305658\n",
      "Check VLAD cosine similarity: -0.06347357354305658\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 4096\n",
      "Length of VLAD vector: 4096\n",
      "VLAD cosine similarity: 0.20899501453494504\n",
      "Check VLAD cosine similarity: 0.20899501453494504\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32768\n",
      "Length of VLAD vector: 32768\n",
      "VLAD cosine similarity: 0.03877009254597492\n",
      "Check VLAD cosine similarity: 0.03877009254597492\n",
      "Test passed\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "cfc581c8e983f570",
   "metadata": {},
   "source": [
    "# 2. Fisher Vector (PASS)"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8fc9d00e6c6d6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T15:36:53.774510Z",
     "start_time": "2024-12-17T15:35:48.444944Z"
    }
   },
   "source": [
    "for i in range(30):\n",
    "    num_cls= np.random.choice([32, 64, 128, 256])\n",
    "    feature = np.random.choice(['sift', 'root_sift'])\n",
    "    dataset_choice = np.random.choice(['train', 'validation'])\n",
    "    if dataset_choice == 'train':\n",
    "        dataset = train_dataset\n",
    "    else:\n",
    "        dataset = test_dataset\n",
    "    print(\"Chosen dataset:\", dataset_choice)\n",
    "    idx_1 = 0\n",
    "    idx_2 = 0\n",
    "    while idx_1 == idx_2:\n",
    "        idx_1 = random.randint(0, len(dataset)-1)\n",
    "        idx_2 = random.randint(0, len(dataset)-1)\n",
    "\n",
    "    image_1, *_ ,path1= dataset[idx_1]\n",
    "    image_2, *_, path2 = dataset[idx_2]\n",
    "    gmm = load_model(f'{ROOT}/models/pickle_model_files/gmm_model_k{num_cls}_{feature}.pkl')\n",
    "\n",
    "    fisher_1 = FisherVector(image_1, gmm=gmm, flatten=True, feature=feature, verbose=False).vector\n",
    "    print(\"Length of VLAD vector:\", len(fisher_1))\n",
    "    fisher_2 = FisherVector(image_2, gmm=gmm, flatten=True, feature=feature, verbose=False).vector\n",
    "    print(\"Length of VLAD vector:\", len(fisher_2))\n",
    "\n",
    "    print(\"Fisher cosine similarity:\", res:=cosine_similarity(fisher_1.reshape(1, -1), fisher_2.reshape(1, -1))[0][0])\n",
    "\n",
    "    hdf_file = load_hdf5(f'{ROOT}/res/fisher/{dataset_choice}/gmm_model_k{num_cls}_{feature}.h5')\n",
    "\n",
    "    fisher_check_1 = hdf_file[os.path.basename(path1)]\n",
    "    fisher_check_2 = hdf_file[os.path.basename(path2)]\n",
    "    print(\"Check Fisher cosine similarity:\", res_check:=cosine_similarity(fisher_check_1.reshape(1, -1), fisher_check_2.reshape(1, -1))[0][0])\n",
    "    if not abs(res - res_check) < 1e-5:\n",
    "        raise ValueError(\"Fisher cosine similarity is not equal to the check value\")\n",
    "\n",
    "print(\"Test passed\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: 0.07895228838656596\n",
      "Check Fisher cosine similarity: 0.07895228838656596\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.05751707274923919\n",
      "Check Fisher cosine similarity: 0.05751707274923919\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: -0.013070390459632975\n",
      "Check Fisher cosine similarity: -0.013070390459632975\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.021015846129207903\n",
      "Check Fisher cosine similarity: 0.021015846129207903\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: -0.042273249011004904\n",
      "Check Fisher cosine similarity: -0.042273249011004904\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16448\n",
      "Length of VLAD vector: 16448\n",
      "Fisher cosine similarity: 0.1062389206315932\n",
      "Check Fisher cosine similarity: 0.1062389206315932\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.027756734775150265\n",
      "Check Fisher cosine similarity: 0.027756734775150265\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: 0.012043416806989183\n",
      "Check Fisher cosine similarity: 0.012043416806989183\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: -0.0025187729795374853\n",
      "Check Fisher cosine similarity: -0.0025187729795374853\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 16448\n",
      "Length of VLAD vector: 16448\n",
      "Fisher cosine similarity: -0.013375441319804775\n",
      "Check Fisher cosine similarity: -0.013375441319804775\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.033152758344557644\n",
      "Check Fisher cosine similarity: 0.033152758344557644\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16448\n",
      "Length of VLAD vector: 16448\n",
      "Fisher cosine similarity: 0.03242557567375094\n",
      "Check Fisher cosine similarity: 0.03242557567375094\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.02341553663529205\n",
      "Check Fisher cosine similarity: 0.02341553663529205\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.02410346118468781\n",
      "Check Fisher cosine similarity: 0.02410346118468781\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: 0.05132629232234909\n",
      "Check Fisher cosine similarity: 0.05132629232234909\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: -0.010752769496994278\n",
      "Check Fisher cosine similarity: -0.010752769496994278\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: 0.0474405272439188\n",
      "Check Fisher cosine similarity: 0.0474405272439188\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: 0.029435736162583544\n",
      "Check Fisher cosine similarity: 0.029435736162583544\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: -0.01897704838984422\n",
      "Check Fisher cosine similarity: -0.01897704838984422\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: -0.002517051337092813\n",
      "Check Fisher cosine similarity: -0.002517051337092813\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 32896\n",
      "Length of VLAD vector: 32896\n",
      "Fisher cosine similarity: 0.0028293322713980286\n",
      "Check Fisher cosine similarity: 0.0028293322713980286\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: 0.05454051801293826\n",
      "Check Fisher cosine similarity: 0.05454051801293826\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: 0.12983900841863638\n",
      "Check Fisher cosine similarity: 0.12983900841863638\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: -0.054564811279874156\n",
      "Check Fisher cosine similarity: -0.054564811279874156\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: -0.010827406793303003\n",
      "Check Fisher cosine similarity: -0.010827406793303003\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16448\n",
      "Length of VLAD vector: 16448\n",
      "Fisher cosine similarity: -0.0123288915845389\n",
      "Check Fisher cosine similarity: -0.0123288915845389\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 16448\n",
      "Length of VLAD vector: 16448\n",
      "Fisher cosine similarity: 0.18267364792010915\n",
      "Check Fisher cosine similarity: 0.18267364792010915\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 8224\n",
      "Length of VLAD vector: 8224\n",
      "Fisher cosine similarity: -0.11044237017928324\n",
      "Check Fisher cosine similarity: -0.11044237017928324\n",
      "Chosen dataset: validation\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: 0.013168137143561279\n",
      "Check Fisher cosine similarity: 0.013168137143561279\n",
      "Chosen dataset: train\n",
      "Length of VLAD vector: 65792\n",
      "Length of VLAD vector: 65792\n",
      "Fisher cosine similarity: -0.028411266440219126\n",
      "Check Fisher cosine similarity: -0.028411266440219126\n",
      "Test passed\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0e30a996f511f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "309cc0e6e0e3e4b",
   "metadata": {},
   "source": "# 3. SSIM, train vs train (PASS)"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-19T13:03:05.078514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(30):\n",
    "    idx_1 = 0\n",
    "    idx_2 = 0\n",
    "    while idx_1 == idx_2:\n",
    "        idx_1 = random.randint(0, len(train_dataset)-1)\n",
    "        idx_2 = random.randint(0, len(train_dataset)-1)\n",
    "\n",
    "    sigma = np.random.choice([0, 2, 4, 6, 8, 10])\n",
    "    print(f\"Chosen sigma for i={i}: \", sigma)\n",
    "    image_1, *_ ,path1= train_dataset[idx_1]\n",
    "    print(path1)\n",
    "    image_2, *_, path2 = train_dataset[idx_2]\n",
    "\n",
    "    image_1 = TRANSFORMER(image_1)\n",
    "    image_2 = TRANSFORMER(image_2)\n",
    "\n",
    "    if sigma != np.array(0):\n",
    "        image_1 = gaussian_blur(image_1, sigma=sigma, kernel_size = 2*int(3*sigma)+1)\n",
    "        image_2 = gaussian_blur(image_2, sigma=sigma, kernel_size = 2*int(3*sigma)+1)\n",
    "\n",
    "    ssim = float(SSIM(image_1, image_2).value.item())\n",
    "    ms_ssim = float(MS_SSIM(image_1, image_2).value.item())\n",
    "\n",
    "    hdf_file = load_hdf5(f'{ROOT}/res/ssim/within_train/ssim_sigma{sigma}_sorted.h5')\n",
    "\n",
    "    path_1_check = None\n",
    "    idx_arr_1 = None\n",
    "    path_2_check = None\n",
    "    idx_arr_2 = None\n",
    "\n",
    "    for i, path in enumerate(hdf_file['image_paths']):\n",
    "        if isinstance(path, bytes):\n",
    "            path = path.decode('utf-8')\n",
    "        if os.path.basename(path1) == os.path.basename(path):\n",
    "            idx_arr_1 = i\n",
    "        if os.path.basename(path2) == os.path.basename(path):\n",
    "            idx_arr_2 = i\n",
    "\n",
    "    ssim_check = hdf_file['ssim'][idx_arr_2]\n",
    "    ms_ssim_check = hdf_file['ms_ssim'][idx_arr_2]\n",
    "    print(\"Check SSIM:\", ssim_res_check:=ssim_check[idx_arr_1])\n",
    "    print(\"Check MS-SSIM:\", ms_ssim_res_check:=ms_ssim_check[idx_arr_1])\n",
    "    if not abs(ssim - ssim_res_check) < 1e-5:\n",
    "       raise ValueError(\"SSIM is not equal to the check value\")\n",
    "    if not abs(ms_ssim - ms_ssim_res_check) < 1e-5:\n",
    "         raise ValueError(\"MS-SSIM is not equal to the check value\")\n",
    "\n",
    "print(\"Test passed\")"
   ],
   "id": "ee95ecdc131b4dba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen sigma for i=0:  0\n",
      "/home/ais/Bachelorarbeit/similarity_metrics_of_images/excavator_dataset_w_masks/train/roller/0040284_jpg.rf.dd54b8924da441588e73fbd80d399bb3.jpg\n",
      "Check SSIM: 0.07677575\n",
      "Check MS-SSIM: 0.029960733\n",
      "Chosen sigma for i=1:  8\n",
      "/home/ais/Bachelorarbeit/similarity_metrics_of_images/excavator_dataset_w_masks/train/caterpillar/002819_jpg.rf.260fcb3d76ccfde90551a3d322442564.jpg\n",
      "Check SSIM: 0.60539484\n",
      "Check MS-SSIM: 0.3891294\n",
      "Chosen sigma for i=2:  4\n",
      "/home/ais/Bachelorarbeit/similarity_metrics_of_images/excavator_dataset_w_masks/train/caterpillar/002650_jpg.rf.225eaea3900c3d06acd34557054cb522.jpg\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. SSIM, train vs val",
   "id": "5ae3fb9dafc7383"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:27:21.652747Z",
     "start_time": "2024-12-23T08:27:21.644883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "torch.__version__"
   ],
   "id": "d065ffc434b69d01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cu124'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "38d7a14f138ea0f8",
   "metadata": {},
   "source": "# 5. Model predictions, IoU, all"
  },
  {
   "cell_type": "code",
   "id": "29787854daa8b5f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:24:52.418216Z",
     "start_time": "2024-12-23T08:24:52.091200Z"
    }
   },
   "source": [
    "# DeepLabV3\n",
    "dlv3 =DeepLabV3Model(model_path=f'{ROOT}/models/torch_model_files/DeepLabV3_HybridFocalDiceLoss.pt')\n",
    "\n",
    "# DeepLabV3Plus\n",
    "dlv3p = DeepLabV3PlusModel(model_path=f'{ROOT}/models/torch_model_files/DeepLabV3Plus_HybridFocalDiceLoss.pt')\n",
    "\n",
    "# UNet\n",
    "unet = UNetModel(model_path=f'{ROOT}/models/torch_model_files/UNet_HybridFocalDiceLoss.pt')\n",
    "\n",
    "# Pyramid Attention Network\n",
    "pan = PyramidAttentionNetworkModel(model_path=f'{ROOT}/models/torch_model_files/PyramidAttentionNetwork_HybridFocalDiceLoss.pt')"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# DeepLabV3\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m dlv3 \u001B[38;5;241m=\u001B[39m\u001B[43mDeepLabV3Model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mROOT\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/models/torch_model_files/DeepLabV3_HybridFocalDiceLoss.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# DeepLabV3Plus\u001B[39;00m\n\u001B[1;32m      5\u001B[0m dlv3p \u001B[38;5;241m=\u001B[39m DeepLabV3PlusModel(model_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mROOT\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/models/torch_model_files/DeepLabV3Plus_HybridFocalDiceLoss.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Bachelorarbeit/similarity_metrics_of_images/models/Segmentation.py:239\u001B[0m, in \u001B[0;36mDeepLabV3Model.__init__\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 239\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDeepLabV3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogger_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDeepLabV3\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Bachelorarbeit/similarity_metrics_of_images/models/Segmentation.py:57\u001B[0m, in \u001B[0;36m_BaseSegmentationModel.__init__\u001B[0;34m(self, model_class, model_path, criterion, optimizer, weight_decay, metrics, activation, encoder_name, encoder_weights, classes, lr, logger_name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m model_class(encoder_name\u001B[38;5;241m=\u001B[39mencoder_name,\n\u001B[1;32m     52\u001B[0m                          encoder_weights\u001B[38;5;241m=\u001B[39mencoder_weights,\n\u001B[1;32m     53\u001B[0m                          classes\u001B[38;5;241m=\u001B[39mclasses,\n\u001B[1;32m     54\u001B[0m                          activation\u001B[38;5;241m=\u001B[39mactivation)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_path:\n\u001B[0;32m---> 57\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mload_state_dict(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mNew \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_class\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m model created with the following info:\u001B[39m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;124m                    - Encoder name: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder_name\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;124m                    - Activation: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;124m                    - Classes: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\"\"\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:1351\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights_only:\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1351\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1352\u001B[0m \u001B[43m            \u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1353\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1354\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_weights_only_unpickler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1355\u001B[0m \u001B[43m            \u001B[49m\u001B[43moverall_storage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverall_storage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1357\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1358\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1359\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:1848\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[1;32m   1846\u001B[0m \u001B[38;5;28;01mglobal\u001B[39;00m _serialization_tls\n\u001B[1;32m   1847\u001B[0m _serialization_tls\u001B[38;5;241m.\u001B[39mmap_location \u001B[38;5;241m=\u001B[39m map_location\n\u001B[0;32m-> 1848\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1849\u001B[0m _serialization_tls\u001B[38;5;241m.\u001B[39mmap_location \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1851\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/_weights_only_unpickler.py:385\u001B[0m, in \u001B[0;36mUnpickler.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    378\u001B[0m         \u001B[38;5;28mtype\u001B[39m(pid) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m\n\u001B[1;32m    379\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(pid) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mserialization\u001B[38;5;241m.\u001B[39m_maybe_decode_ascii(pid[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstorage\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    381\u001B[0m     ):\n\u001B[1;32m    382\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m UnpicklingError(\n\u001B[1;32m    383\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly persistent_load of storage is allowed, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpid[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    384\u001B[0m         )\n\u001B[0;32m--> 385\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpersistent_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpid\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m [BINGET[\u001B[38;5;241m0\u001B[39m], LONG_BINGET[\u001B[38;5;241m0\u001B[39m]]:\n\u001B[1;32m    387\u001B[0m     idx \u001B[38;5;241m=\u001B[39m (read(\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m key[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m==\u001B[39m BINGET[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01melse\u001B[39;00m unpack(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<I\u001B[39m\u001B[38;5;124m\"\u001B[39m, read(\u001B[38;5;241m4\u001B[39m)))[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:1812\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m   1810\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1811\u001B[0m     nbytes \u001B[38;5;241m=\u001B[39m numel \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_element_size(dtype)\n\u001B[0;32m-> 1812\u001B[0m     typed_storage \u001B[38;5;241m=\u001B[39m \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1813\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1814\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1816\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m typed_storage\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:1784\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(dtype, numel, key, location)\u001B[0m\n\u001B[1;32m   1779\u001B[0m         storage\u001B[38;5;241m.\u001B[39mbyteswap(dtype)\n\u001B[1;32m   1781\u001B[0m \u001B[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001B[39;00m\n\u001B[1;32m   1782\u001B[0m \u001B[38;5;66;03m# stop wrapping with TypedStorage\u001B[39;00m\n\u001B[1;32m   1783\u001B[0m typed_storage \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstorage\u001B[38;5;241m.\u001B[39mTypedStorage(\n\u001B[0;32m-> 1784\u001B[0m     wrap_storage\u001B[38;5;241m=\u001B[39m\u001B[43mrestore_location\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1785\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mdtype,\n\u001B[1;32m   1786\u001B[0m     _internal\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m   1787\u001B[0m )\n\u001B[1;32m   1789\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typed_storage\u001B[38;5;241m.\u001B[39m_data_ptr() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1790\u001B[0m     loaded_storages[key] \u001B[38;5;241m=\u001B[39m typed_storage\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:601\u001B[0m, in \u001B[0;36mdefault_restore_location\u001B[0;34m(storage, location)\u001B[0m\n\u001B[1;32m    581\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001B[39;00m\n\u001B[1;32m    583\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;124;03m       all matching ones return `None`.\u001B[39;00m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    600\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, _, fn \u001B[38;5;129;01min\u001B[39;00m _package_registry:\n\u001B[0;32m--> 601\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    602\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    603\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:539\u001B[0m, in \u001B[0;36m_deserialize\u001B[0;34m(backend_name, obj, location)\u001B[0m\n\u001B[1;32m    537\u001B[0m     backend_name \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_get_privateuse1_backend_name()\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m location\u001B[38;5;241m.\u001B[39mstartswith(backend_name):\n\u001B[0;32m--> 539\u001B[0m     device \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_device\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "File \u001B[0;32m~/.virtualenvs/similarity_metrics_of_images/lib/python3.12/site-packages/torch/serialization.py:508\u001B[0m, in \u001B[0;36m_validate_device\u001B[0;34m(location, backend_name)\u001B[0m\n\u001B[1;32m    506\u001B[0m     device_index \u001B[38;5;241m=\u001B[39m device\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;28;01mif\u001B[39;00m device\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(device_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_available\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m device_module\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[0;32m--> 508\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    509\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting to deserialize object on a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend_name\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    510\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice but torch.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.is_available() is False. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    511\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you are running on a CPU-only machine, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    512\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease use torch.load with map_location=torch.device(\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto map your storages to the CPU.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    514\u001B[0m     )\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(device_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice_count\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    516\u001B[0m     device_count \u001B[38;5;241m=\u001B[39m device_module\u001B[38;5;241m.\u001B[39mdevice_count()\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "5f068fd5c959dabf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:24:47.282719Z",
     "start_time": "2024-12-23T08:24:47.250073Z"
    }
   },
   "source": [
    "def plot_image_and_mask(image: torch.Tensor, gt_mask: torch.Tensor, pred_mask: torch.Tensor=None):\n",
    "    \"\"\"\n",
    "    Plot image, ground truth mask and predicted mask (if available).\n",
    "\n",
    "    :param image:\n",
    "    :param gt_mask:\n",
    "    :param pred_mask:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    if image.shape[0] == 3:\n",
    "        image = image.permute(1, 2, 0)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if gt_mask.shape[0] == 3:\n",
    "        gt_mask = gt_mask.permute(1, 2, 0)\n",
    "    plt.imshow(gt_mask)\n",
    "    plt.axis('off')\n",
    "    plt.title('Ground Truth Mask')\n",
    "\n",
    "    if pred_mask is None:\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if pred_mask.shape[0] == 3:\n",
    "        pred_mask = pred_mask.permute(1, 2, 0)\n",
    "    plt.imshow(pred_mask)\n",
    "    plt.axis('off')\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(2):\n",
    "    idx = random.randint(0, len(train_dataset)-1)\n",
    "    model = np.random.choice([dlv3, dlv3p, unet, pan])\n",
    "    print(\"Chosen model:\", model.model.__class__.__name__)\n",
    "\n",
    "    dataset_choice = np.random.choice(['train', 'val'])\n",
    "    if dataset_choice == 'train':\n",
    "        dataset = train_dataset\n",
    "    else:\n",
    "        dataset = test_dataset\n",
    "\n",
    "    image, mask, path = dataset[idx]\n",
    "    path_basename = os.path.basename(path)\n",
    "\n",
    "    image = TRANSFORMER(image)\n",
    "\n",
    "    mask = TRANSFORMER(mask)\n",
    "    mask = rgb_to_mask(mask, cls_colors)\n",
    "\n",
    "\n",
    "    _, pred_mask = model.predict_single_image(image, mask, raw_output=False)\n",
    "\n",
    "    _, raw_pred= model.predict_single_image(image, mask, raw_output=True)\n",
    "    mask_one_hot = one_hot(mask, num_classes=12).permute(2, 0, 1)\n",
    "    iou_manual = multiclass_iou(mask_one_hot, raw_pred)\n",
    "\n",
    "    model_paths = {\n",
    "        dlv3: f'{ROOT}/res/model_performance/{dataset_choice}_iou_dlv3.h5',\n",
    "        dlv3p: f'{ROOT}/res/model_performance/{dataset_choice}_iou_dlv3p.h5',\n",
    "        unet: f'{ROOT}/res/model_performance/{dataset_choice}_iou_unet.h5',\n",
    "        pan: f'{ROOT}/res/model_performance/{dataset_choice}_iou_pan.h5'\n",
    "    }\n",
    "\n",
    "    iou_data = load_hdf5(model_paths[model])\n",
    "    target_iou = iou_data[path_basename]\n",
    "\n",
    "    if not abs(iou_manual - target_iou) < 1e-5:\n",
    "        raise ValueError(\"IoU difference is not equal to the check value\")\n",
    "\n",
    "    plot_image_and_mask(image, mask, pred_mask)\n",
    "print(\"All tests passed\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlv3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 38\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m     37\u001B[0m     idx \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(train_dataset)\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 38\u001B[0m     model \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice([\u001B[43mdlv3\u001B[49m, dlv3p, unet, pan])\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChosen model:\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m     41\u001B[0m     dataset_choice \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'dlv3' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Model predictions, IoU, only classes contained in train mask",
   "id": "434aeecbcd7c68d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T08:48:17.424974Z",
     "start_time": "2024-12-23T08:48:17.305136Z"
    }
   },
   "cell_type": "code",
   "source": "data = load_hdf5(f'{ROOT}/res/confidence_vectors/dlv3_only_classes_in_train.h5')",
   "id": "ee07b8a9a0d556df",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_hdf5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mload_hdf5\u001B[49m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mROOT\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/res/confidence_vectors/dlv3_only_classes_in_train.h5\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'load_hdf5' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c927913fd946a0ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
